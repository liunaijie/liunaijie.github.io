<!DOCTYPE html>
<html lang="zh-CN">

<head>

  <!-- Minima -->
  <!-- Hexo theme created by @adisaktijrs -->

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">

  
  <title>Spark中的提交流程</title>
  
  <link rel="canonical" href="https://www.liunaijie.top/2023/07/22/Blog-Posts/publish/Spark%E7%9A%84%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B/">
  
  <meta name="description" content="本文以Spark3.4版本，提交任务方式为Yarn Cluster，以JavaWordCount这个应用程序为例来分析一下一个Spark任务的提交过程。过程中会对代码做一些删减，主要目的是了解从用户提交任务开始到一个任务如何开始运行.本文主要记录两种提交任务的方式，spark-submit.sh与S">
  
  
  <meta name="keywords" content="blog">
  
  <meta name="author" content="Jarvis">
  
  
  
  <meta property="og:site_name" content="J.A.R.V.I.S" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="Spark中的提交流程" />
  
  <meta property="og:description" content="本文以Spark3.4版本，提交任务方式为Yarn Cluster，以JavaWordCount这个应用程序为例来分析一下一个Spark任务的提交过程。过程中会对代码做一些删减，主要目的是了解从用户提交任务开始到一个任务如何开始运行.本文主要记录两种提交任务的方式，spark-submit.sh与S">
  
  <meta property="og:url" content="https://www.liunaijie.top/2023/07/22/Blog-Posts/publish/Spark%E7%9A%84%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B/" />

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Spark中的提交流程">
  
  <meta name="twitter:description" content="本文以Spark3.4版本，提交任务方式为Yarn Cluster，以JavaWordCount这个应用程序为例来分析一下一个Spark任务的提交过程。过程中会对代码做一些删减，主要目的是了解从用户提交任务开始到一个任务如何开始运行.本文主要记录两种提交任务的方式，spark-submit.sh与S">
  
  
  
  
  <meta name="twitter:url" content="https://www.liunaijie.top/2023/07/22/Blog-Posts/publish/Spark%E7%9A%84%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B/" />

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Preload fonts
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="preload" href="/fonts/dm-serif-display-v4-latin-regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="/fonts/inter-v2-latin-regular.woff2" as="font" type="font/woff2" crossorigin>

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  
<link rel="stylesheet" href="/css/normalize.css">

  
<link rel="stylesheet" href="/css/skeleton.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
<link rel="stylesheet" href="/css/prism-dark.css">

  
<link rel="stylesheet" href="/css/prism-line-numbers.css">

  <!-- User css -->
  

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="/images/jarvis.png">

  <!-- Custom Theme Color Style
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <style>
  a:not(.icon) {
    text-decoration-color: #0FA0CE;
    background-image: linear-gradient(
      to bottom,
      rgba(0, 0, 0, 0) 50%,
      #0FA0CE 50%
    );
  }
  blockquote {
    border-left: 8px solid #0FA0CE;
  }
  .nanobar .bar {
    background: #0FA0CE;
  }
  .button.button-primary:hover,
  button.button-primary:hover,
  input[type="submit"].button-primary:hover,
  input[type="reset"].button-primary:hover,
  input[type="button"].button-primary:hover,
  .button.button-primary:focus,
  button.button-primary:focus,
  input[type="submit"].button-primary:focus,
  input[type="reset"].button-primary:focus,
  input[type="button"].button-primary:focus {
    background-color: #0FA0CE;
    border-color: #0FA0CE;
  }
  input[type="email"]:focus,
  input[type="number"]:focus,
  input[type="search"]:focus,
  input[type="text"]:focus,
  input[type="tel"]:focus,
  input[type="url"]:focus,
  input[type="password"]:focus,
  textarea:focus,
  select:focus {
    border: 1px solid #0FA0CE;
  }
</style>

  <!-- Google Analytics (With Privacy Settings On)
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  

  
  <script src="/js/pic.min.js" defer></script>
  

  

<meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="J.A.R.V.I.S" type="application/atom+xml">
</head>

<body>
  <div class="container">
    <div class="row">
      <div>

        <div class="row">
  <div class="two columns" style="max-width: 50px">
    <h1 class="mt-2 mode">
      <div onclick=setDarkMode(true) id="darkBtn"></div>
      <div onclick=setDarkMode(false) id="lightBtn" class=hidden></div>
      <script >
        if (localStorage.getItem('preferredTheme') == 'dark') {
          setDarkMode(true)
        }
        function setDarkMode(isDark) {
          var darkBtn = document.getElementById('darkBtn')
          var lightBtn = document.getElementById('lightBtn')
          if (isDark) {
            lightBtn.style.display = "block"
            darkBtn.style.display = "none"
            localStorage.setItem('preferredTheme', 'dark');
          } else {
            lightBtn.style.display = "none"
            darkBtn.style.display = "block"
            localStorage.removeItem('preferredTheme');
          }
          document.body.classList.toggle("darkmode");
        }
      </script>
    </h1>
  </div>

  <div class="six columns ml-1">
    <h1 class="mt-2">
      Jarvis&#39;s Blog
    </h1>
  </div>

  <div class="twelve columns">
    <div class="row">
      <div class="nine columns left">
        
          
          <a href="/" class="ml">Home</a>
          
        
          
          <a href="/categories/publish/" class="ml">Publish</a>
          
        
          
          <a href="/about" class="ml">About</a>
          
        
          
          <a href="/atom.xml" class="ml">Rss</a>
          
        
      </div>
    </div>
    <hr style="margin-bottom: 2.6rem">
  </div>
</div>

        <div class="trans">
            <h2>Spark中的提交流程</h2>

  <p>本文以Spark3.4版本，提交任务方式为Yarn Cluster，以<code>JavaWordCount</code>这个应用程序为例来分析一下一个Spark任务的提交过程。<br>过程中会对代码做一些删减，主要目的是了解从用户提交任务开始到一个任务如何开始运行.<br>本文主要记录两种提交任务的方式，<code>spark-submit.sh</code>与<code>SparkLauncher</code>.  </p>
<h1 id="Spark-submit-sh"><a href="#Spark-submit-sh" class="headerlink" title="Spark-submit.sh"></a>Spark-submit.sh</h1><p>以需要执行JavaWordCount为例，启动命令为：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit \</span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">--class org.apache.spark.examples.JavaWordCount \</span><br><span class="line">/path/to/examples.jar \</span><br><span class="line">/tmp/file1.txt</span><br></pre></td></tr></table></figure>
<p>我们指定了在yarn上以cluster模式启动JavaWordCount程序， 指定了jar包位置，以及要读取的文件</p>
<h2 id="spark-submit"><a href="#spark-submit" class="headerlink" title="spark-submit"></a>spark-submit</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line"></span><br><span class="line">exec &quot;$&#123;SPARK_HOME&#125;&quot;/bin/spark-class org.apache.spark.deploy.SparkSubmit &quot;$@&quot;</span><br></pre></td></tr></table></figure>
<p>这个脚本最后调用了<code>spark-class</code>脚本，第一个参数为<code>SparkSubmit</code>的全类名，再加上我们本来的参数</p>
<h2 id="spark-class"><a href="#spark-class" class="headerlink" title="spark-class"></a>spark-class</h2><p>这个脚本做了这几件事：</p>
<ul>
<li>查找spark的jar包<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Find Spark jars.</span>  </span><br><span class="line">if [ -d &quot;$&#123;SPARK_HOME&#125;/jars&quot; ]; then  </span><br><span class="line">SPARK_JARS_DIR=&quot;$&#123;SPARK_HOME&#125;/jars&quot;  </span><br><span class="line">else  </span><br><span class="line">SPARK_JARS_DIR=&quot;$&#123;SPARK_HOME&#125;/assembly/target/scala-$SPARK_SCALA_VERSION/jars&quot;  </span><br><span class="line">fi  </span><br><span class="line">  </span><br><span class="line">if [ ! -d &quot;$SPARK_JARS_DIR&quot; ] &amp;&amp; [ -z &quot;$SPARK_TESTING$SPARK_SQL_TESTING&quot; ]; then  </span><br><span class="line">echo &quot;Failed to find Spark jars directory ($SPARK_JARS_DIR).&quot; 1&gt;&amp;2  </span><br><span class="line">echo &quot;You need to build Spark with the target \&quot;package\&quot; before running this program.&quot; 1&gt;&amp;2  </span><br><span class="line">exit 1  </span><br><span class="line">else  </span><br><span class="line">LAUNCH_CLASSPATH=&quot;$SPARK_JARS_DIR/*&quot;  </span><br><span class="line">fi  </span><br><span class="line"><span class="meta prompt_">  </span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Add the launcher build <span class="built_in">dir</span> to the classpath <span class="keyword">if</span> requested.</span>  </span><br><span class="line">if [ -n &quot;$SPARK_PREPEND_CLASSES&quot; ]; then  </span><br><span class="line">LAUNCH_CLASSPATH=&quot;$&#123;SPARK_HOME&#125;/launcher/target/scala-$SPARK_SCALA_VERSION/classes:$LAUNCH_CLASSPATH&quot;  </span><br><span class="line">fi</span><br></pre></td></tr></table></figure></li>
<li>调用SparkLauncher里面的Main进行参数注入<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">build_command() &#123;  </span><br><span class="line">&quot;$RUNNER&quot; -Xmx128m $SPARK_LAUNCHER_OPTS -cp &quot;$LAUNCH_CLASSPATH&quot; org.apache.spark.launcher.Main &quot;$@&quot;  </span><br><span class="line">printf &quot;%d\0&quot; $?  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>执行被修改过的命令<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CMD=(&quot;$&#123;CMD[@]:0:$LAST&#125;&quot;)  </span><br><span class="line">exec &quot;$&#123;CMD[@]&#125;&quot;</span><br></pre></td></tr></table></figure>
经过修改后最终的命令为：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">java -cp</span><br><span class="line">....(一些参数修改)</span><br><span class="line">org.apache.spark.deploy.SparkSubmit \ </span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">--class org.apache.spark.examples.JavaWordCount \</span><br><span class="line">/path/to/examples.jar \</span><br><span class="line">/tmp/file1.txt</span><br></pre></td></tr></table></figure>
可以看到这里最终会去调用<code>SparkSubmit</code>这个类</li>
</ul>
<h2 id="SparkSubmit"><a href="#SparkSubmit" class="headerlink" title="SparkSubmit"></a>SparkSubmit</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;  </span><br><span class="line">	<span class="keyword">val</span> submit = <span class="keyword">new</span> <span class="type">SparkSubmit</span>() &#123;  </span><br><span class="line">		self =&gt;  </span><br><span class="line">			<span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">doSubmit</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;  </span><br><span class="line">		<span class="keyword">try</span> &#123;  </span><br><span class="line">			<span class="comment">// 调用 doSubmit方法  </span></span><br><span class="line">			<span class="keyword">super</span>.doSubmit(args)  </span><br><span class="line">			&#125; <span class="keyword">catch</span> &#123;  </span><br><span class="line">			<span class="keyword">case</span> e: <span class="type">SparkUserAppException</span> =&gt;  </span><br><span class="line">				exitFn(e.exitCode)  </span><br><span class="line">			&#125;  </span><br><span class="line">		&#125;  </span><br><span class="line">	&#125;  </span><br><span class="line">	submit.doSubmit(args)  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">SparkSubmit</span> <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">doSubmit</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;  </span><br><span class="line">		<span class="comment">// Initialize logging if it hasn&#x27;t been done yet. Keep track of whether logging needs to  </span></span><br><span class="line">		<span class="comment">// be reset before the application starts.  </span></span><br><span class="line">		<span class="keyword">val</span> uninitLog = initializeLogIfNecessary(<span class="literal">true</span>, silent = <span class="literal">true</span>)  </span><br><span class="line">		  </span><br><span class="line">		<span class="keyword">val</span> appArgs = parseArguments(args)  </span><br><span class="line">		<span class="keyword">if</span> (appArgs.verbose) &#123;  </span><br><span class="line">			logInfo(appArgs.toString)  </span><br><span class="line">		&#125;  </span><br><span class="line">		<span class="comment">// action默认为submit，则会到submit方法  </span></span><br><span class="line">		appArgs.action <span class="keyword">match</span> &#123;  </span><br><span class="line">			<span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">SUBMIT</span> =&gt; submit(appArgs, uninitLog)  </span><br><span class="line">			<span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">KILL</span> =&gt; kill(appArgs)  </span><br><span class="line">			<span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">REQUEST_STATUS</span> =&gt; requestStatus(appArgs)  </span><br><span class="line">			<span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">PRINT_VERSION</span> =&gt; printVersion()  </span><br><span class="line">		&#125;  </span><br><span class="line">	&#125;</span><br><span class="line">	...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submit</span></span>(args: <span class="type">SparkSubmitArguments</span>, uninitLog: <span class="type">Boolean</span>): <span class="type">Unit</span> = &#123;  </span><br><span class="line">		doRunMain()  </span><br><span class="line">	</span><br><span class="line">		<span class="function"><span class="keyword">def</span> <span class="title">doRunMain</span></span>(): <span class="type">Unit</span> = &#123;  </span><br><span class="line">			...</span><br><span class="line">			runMain(args, uninitLog)  </span><br><span class="line">		&#125;</span><br><span class="line">	 </span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在Main方法中调用伴生类中的<code>doSubmit</code>方法，在<code>doSubmit</code>方法中先进行了参数解析，然后模式匹配，调用不同类型的方法。默认的action为submit，所以会调用到submit方法，而submit方法中又会调用到runMain方法中去.  </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">runMain</span></span>(args: <span class="type">SparkSubmitArguments</span>, uninitLog: <span class="type">Boolean</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">val</span> (childArgs, childClasspath, sparkConf, childMainClass) = prepareSubmitEnvironment(args)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">val</span> loader = getSubmitClassLoader(sparkConf)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> (jar &lt;- childClasspath) &#123;</span><br><span class="line">		addJarToClasspath(jar, loader)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">var</span> mainClass: <span class="type">Class</span>[_] = <span class="literal">null</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">	mainClass = <span class="type">Utils</span>.classForName(childMainClass)</span><br><span class="line">	&#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">val</span> app: <span class="type">SparkApplication</span> = <span class="keyword">if</span> (classOf[<span class="type">SparkApplication</span>].isAssignableFrom(mainClass)) &#123;</span><br><span class="line">	mainClass.getConstructor().newInstance().asInstanceOf[<span class="type">SparkApplication</span>]</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">	<span class="keyword">new</span> <span class="type">JavaMainApplication</span>(mainClass)</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		app.start(childArgs.toArray, sparkConf)</span><br><span class="line">	&#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">	&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在这个方法中，我们可以看到做了这样几件事：</p>
<ul>
<li>获取class loader</li>
<li>获取mainClass并进行初始化</li>
<li>调用实例的start方法<br>我们这里需要关注的点是实例化了那个类，也就是childMainClass是什么，看一下<code>prepareSubmitEnvironment</code>方法<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[deploy] <span class="function"><span class="keyword">def</span> <span class="title">prepareSubmitEnvironment</span></span>(  </span><br><span class="line">args: <span class="type">SparkSubmitArguments</span>,  </span><br><span class="line">conf: <span class="type">Option</span>[<span class="type">HadoopConfiguration</span>] = <span class="type">None</span>)  </span><br><span class="line">: (<span class="type">Seq</span>[<span class="type">String</span>], <span class="type">Seq</span>[<span class="type">String</span>], <span class="type">SparkConf</span>, <span class="type">String</span>) = &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (deployMode == <span class="type">CLIENT</span>) &#123;  </span><br><span class="line">		childMainClass = args.mainClass </span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">if</span> (isYarnCluster) &#123;  </span><br><span class="line">		childMainClass = <span class="type">YARN_CLUSTER_SUBMIT_CLASS</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// Load any properties specified through --conf and the default properties file  </span></span><br><span class="line">	<span class="keyword">for</span> ((k, v) &lt;- args.sparkProperties) &#123;  </span><br><span class="line">		sparkConf.setIfMissing(k, v)  </span><br><span class="line">	&#125;  </span><br><span class="line">	<span class="comment">// Ignore invalid spark.driver.host in cluster modes.  </span></span><br><span class="line">	<span class="keyword">if</span> (deployMode == <span class="type">CLUSTER</span>) &#123;  </span><br><span class="line">		sparkConf.remove(<span class="type">DRIVER_HOST_ADDRESS</span>)  </span><br><span class="line">	&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
这个方法比较复杂，我只摘出来了与这次分析相关或比较重要的几句代码。<br>首先，如果我们使用的是client模式来提交任务，这里的childMainClass就是我们参数中的class，也就是<code>JavaWordCount</code>的全类名。<br>如果我们使用的是Yarn Cluster模式，这里的childMainClass则为<code>org.apache.spark.deploy.yarn.YarnClusterApplication</code>.<br>后续还会将我们参数中的spark配置读取并进行配置。</li>
</ul>
<p>再回到<code>runMain</code>这个方法中，</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">runMain</span></span>(args: <span class="type">SparkSubmitArguments</span>, uninitLog: <span class="type">Boolean</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">val</span> (childArgs, childClasspath, sparkConf, childMainClass) = prepareSubmitEnvironment(args)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">val</span> loader = getSubmitClassLoader(sparkConf)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> (jar &lt;- childClasspath) &#123;</span><br><span class="line">		addJarToClasspath(jar, loader)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">var</span> mainClass: <span class="type">Class</span>[_] = <span class="literal">null</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		mainClass = <span class="type">Utils</span>.classForName(childMainClass)</span><br><span class="line">	&#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">val</span> app: <span class="type">SparkApplication</span> = <span class="keyword">if</span> (classOf[<span class="type">SparkApplication</span>].isAssignableFrom(mainClass)) &#123;</span><br><span class="line">	mainClass.getConstructor().newInstance().asInstanceOf[<span class="type">SparkApplication</span>]</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">	<span class="keyword">new</span> <span class="type">JavaMainApplication</span>(mainClass)</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		app.start(childArgs.toArray, sparkConf)</span><br><span class="line">	&#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">	&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>先来分析Client模式，这里得到的childMainClass为我们提交的任务类，在我们的例子中为<code>JavaWordCount</code>. 这个在初始化时会使用<code>JavaMainApplication</code>做一下封装。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[deploy] <span class="class"><span class="keyword">class</span> <span class="title">JavaMainApplication</span>(<span class="params">klass: <span class="type">Class</span>[_]</span>) <span class="keyword">extends</span> <span class="title">SparkApplication</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">start</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>], conf: <span class="type">SparkConf</span>): <span class="type">Unit</span> = &#123;  </span><br><span class="line"><span class="keyword">val</span> mainMethod = klass.getMethod(<span class="string">&quot;main&quot;</span>, <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">String</span>](<span class="number">0</span>).getClass)  </span><br><span class="line"><span class="keyword">if</span> (!<span class="type">Modifier</span>.isStatic(mainMethod.getModifiers)) &#123;  </span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">&quot;The main method in the given main class must be static&quot;</span>)  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">val</span> sysProps = conf.getAll.toMap  </span><br><span class="line">sysProps.foreach &#123; <span class="keyword">case</span> (k, v) =&gt;  </span><br><span class="line">sys.props(k) = v  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">mainMethod.invoke(<span class="literal">null</span>, args)  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当我们调用<code>app.start</code>时，其实就是调用了<code>JavaWordCount</code>这个类的main方法。<br>可以看到在Client模式下，直接在本地启动了我们的程序，也就是Driver是在本地进行启动。</p>
<p>再来分析一下Cluster模式下的启动，<code>childMainClass</code>得到的值是<code>YarnClusterApplication</code>.</p>
<h2 id="YarnClusterApplication"><a href="#YarnClusterApplication" class="headerlink" title="YarnClusterApplication"></a>YarnClusterApplication</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">YarnClusterApplication</span> <span class="keyword">extends</span> <span class="title">SparkApplication</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">	<span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">start</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>], conf: <span class="type">SparkConf</span>): <span class="type">Unit</span> = &#123;  </span><br><span class="line">		<span class="comment">// SparkSubmit would use yarn cache to distribute files &amp; jars in yarn mode,  </span></span><br><span class="line">		<span class="comment">// so remove them from sparkConf here for yarn mode.  </span></span><br><span class="line">		conf.remove(<span class="type">JARS</span>)  </span><br><span class="line">		conf.remove(<span class="type">FILES</span>)  </span><br><span class="line">		conf.remove(<span class="type">ARCHIVES</span>)  </span><br><span class="line">		<span class="keyword">new</span> <span class="type">Client</span>(<span class="keyword">new</span> <span class="type">ClientArguments</span>(args), conf, <span class="literal">null</span>).run()  </span><br><span class="line">	&#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由于<code>YarnClusterApplication</code>是<code>SparkApplication</code>的子类，所以会直接构建实例，然后调用start方法。 在<code>YarnClusterApplication</code>的start方法中，我们看到是初始化了<code>Client</code>然后调用run方法，接下来我们看下<code>Client</code>的实现</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">	submitApplication()</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">submitApplication</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">	<span class="type">ResourceRequestHelper</span>.validateResources(sparkConf)</span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		launcherBackend.connect()</span><br><span class="line">		yarnClient.init(hadoopConf)</span><br><span class="line">		yarnClient.start()</span><br><span class="line">		<span class="comment">// Get a new application from our RM</span></span><br><span class="line">		<span class="keyword">val</span> newApp = yarnClient.createApplication()</span><br><span class="line">		<span class="keyword">val</span> newAppResponse = newApp.getNewApplicationResponse()</span><br><span class="line">		<span class="keyword">this</span>.appId = newAppResponse.getApplicationId()</span><br><span class="line">		<span class="comment">// The app staging dir based on the STAGING_DIR configuration if configured</span></span><br><span class="line">		<span class="comment">// otherwise based on the users home directory.</span></span><br><span class="line">		<span class="comment">// scalastyle:off FileSystemGet</span></span><br><span class="line">		<span class="keyword">val</span> appStagingBaseDir = sparkConf.get(<span class="type">STAGING_DIR</span>)</span><br><span class="line">		.map &#123;</span><br><span class="line">			<span class="keyword">new</span> <span class="type">Path</span>(_, <span class="type">UserGroupInformation</span>.getCurrentUser.getShortUserName)</span><br><span class="line">		&#125;.getOrElse(<span class="type">FileSystem</span>.get(hadoopConf).getHomeDirectory())</span><br><span class="line">		stagingDirPath = <span class="keyword">new</span> <span class="type">Path</span>(appStagingBaseDir, getAppStagingDir(appId))</span><br><span class="line">		<span class="comment">// scalastyle:on FileSystemGet</span></span><br><span class="line">		<span class="keyword">new</span> <span class="type">CallerContext</span>(<span class="string">&quot;CLIENT&quot;</span>, sparkConf.get(<span class="type">APP_CALLER_CONTEXT</span>),</span><br><span class="line">		<span class="type">Option</span>(appId.toString)).setCurrentContext()</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// Verify whether the cluster has enough resources for our AM</span></span><br><span class="line">		verifyClusterResources(newAppResponse)</span><br><span class="line">		<span class="comment">// Set up the appropriate contexts to launch our AM</span></span><br><span class="line">		<span class="keyword">val</span> containerContext = createContainerLaunchContext()</span><br><span class="line">		<span class="keyword">val</span> appContext = createApplicationSubmissionContext(newApp, containerContext)</span><br><span class="line">		<span class="comment">// Finally, submit and monitor the application</span></span><br><span class="line">		logInfo(<span class="string">s&quot;Submitting application <span class="subst">$appId</span> to ResourceManager&quot;</span>)</span><br><span class="line">		<span class="comment">// 提交application</span></span><br><span class="line">		yarnClient.submitApplication(appContext)</span><br><span class="line">		launcherBackend.setAppId(appId.toString)</span><br><span class="line">		reportLauncherState(<span class="type">SparkAppHandle</span>.<span class="type">State</span>.<span class="type">SUBMITTED</span>)</span><br><span class="line">	&#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</span><br><span class="line">			<span class="keyword">if</span> (stagingDirPath != <span class="literal">null</span>) &#123;</span><br><span class="line">				cleanupStagingDir()</span><br><span class="line">			&#125;</span><br><span class="line">		<span class="keyword">throw</span> e</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>分析这一段代码后我们可以知道，这里做的事情就是向Yarn集群申请启动了一个Application，也就是Application Master。在spark里就是Driver。<br>我们看一下这个app的具体信息，<code>createContainerLaunchContext</code>这个方法里面。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">createContainerLaunchContext</span></span>(): <span class="type">ContainerLaunchContext</span> = &#123;</span><br><span class="line"></span><br><span class="line">logInfo(<span class="string">&quot;Setting up container launch context for our AM&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> launchEnv = setupLaunchEnv(stagingDirPath, pySparkArchives)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> localResources = prepareLocalResources(stagingDirPath, pySparkArchives)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> amContainer = <span class="type">Records</span>.newRecord(classOf[<span class="type">ContainerLaunchContext</span>])</span><br><span class="line"></span><br><span class="line">amContainer.setLocalResources(localResources.asJava)</span><br><span class="line"></span><br><span class="line">amContainer.setEnvironment(launchEnv.asJava)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> javaOpts = <span class="type">ListBuffer</span>[<span class="type">String</span>]()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">javaOpts += <span class="string">s&quot;-Djava.net.preferIPv6Addresses=<span class="subst">$&#123;Utils.preferIPv6&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// SPARK-37106: To start AM with Java 17, `JavaModuleOptions.defaultModuleOptions`</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// is added by default. It will not affect Java 8 and Java 11 due to existence of</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// `-XX:+IgnoreUnrecognizedVMOptions`.</span></span><br><span class="line"></span><br><span class="line">javaOpts += <span class="type">JavaModuleOptions</span>.defaultModuleOptions()</span><br><span class="line"></span><br><span class="line"><span class="comment">// Set the environment variable through a command prefix</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// to append to the existing value of the variable</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> prefixEnv: <span class="type">Option</span>[<span class="type">String</span>] = <span class="type">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Add Xmx for AM memory</span></span><br><span class="line"></span><br><span class="line">javaOpts += <span class="string">&quot;-Xmx&quot;</span> + amMemory + <span class="string">&quot;m&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> tmpDir = <span class="keyword">new</span> <span class="type">Path</span>(<span class="type">Environment</span>.<span class="type">PWD</span>.$$(), <span class="type">YarnConfiguration</span>.<span class="type">DEFAULT_CONTAINER_TEMP_DIR</span>)</span><br><span class="line"></span><br><span class="line">javaOpts += <span class="string">&quot;-Djava.io.tmpdir=&quot;</span> + tmpDir</span><br><span class="line"></span><br><span class="line"><span class="comment">// Include driver-specific java options if we are launching a driver</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (isClusterMode) &#123;</span><br><span class="line"></span><br><span class="line">sparkConf.get(<span class="type">DRIVER_JAVA_OPTIONS</span>).foreach &#123; opts =&gt;</span><br><span class="line"></span><br><span class="line">javaOpts ++= <span class="type">Utils</span>.splitCommandString(opts)</span><br><span class="line"></span><br><span class="line">.map(<span class="type">Utils</span>.substituteAppId(_, <span class="keyword">this</span>.appId.toString))</span><br><span class="line"></span><br><span class="line">.map(<span class="type">YarnSparkHadoopUtil</span>.escapeForShell)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> libraryPaths = <span class="type">Seq</span>(sparkConf.get(<span class="type">DRIVER_LIBRARY_PATH</span>),</span><br><span class="line"></span><br><span class="line">sys.props.get(<span class="string">&quot;spark.driver.libraryPath&quot;</span>)).flatten</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (libraryPaths.nonEmpty) &#123;</span><br><span class="line"></span><br><span class="line">prefixEnv = <span class="type">Some</span>(createLibraryPathPrefix(libraryPaths.mkString(<span class="type">File</span>.pathSeparator),</span><br><span class="line"></span><br><span class="line">sparkConf))</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (sparkConf.get(<span class="type">AM_JAVA_OPTIONS</span>).isDefined) &#123;</span><br><span class="line"></span><br><span class="line">logWarning(<span class="string">s&quot;<span class="subst">$&#123;AM_JAVA_OPTIONS.key&#125;</span> will not take effect in cluster mode&quot;</span>)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Validate and include yarn am specific java options in yarn-client mode.</span></span><br><span class="line"></span><br><span class="line">sparkConf.get(<span class="type">AM_JAVA_OPTIONS</span>).foreach &#123; opts =&gt;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (opts.contains(<span class="string">&quot;-Dspark&quot;</span>)) &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> msg = <span class="string">s&quot;<span class="subst">$&#123;AM_JAVA_OPTIONS.key&#125;</span> is not allowed to set Spark options (was &#x27;<span class="subst">$opts</span>&#x27;).&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(msg)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (opts.contains(<span class="string">&quot;-Xmx&quot;</span>)) &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> msg = <span class="string">s&quot;<span class="subst">$&#123;AM_JAVA_OPTIONS.key&#125;</span> is not allowed to specify max heap memory settings &quot;</span> +</span><br><span class="line"></span><br><span class="line"><span class="string">s&quot;(was &#x27;<span class="subst">$opts</span>&#x27;). Use spark.yarn.am.memory instead.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(msg)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">javaOpts ++= <span class="type">Utils</span>.splitCommandString(opts)</span><br><span class="line"></span><br><span class="line">.map(<span class="type">Utils</span>.substituteAppId(_, <span class="keyword">this</span>.appId.toString))</span><br><span class="line"></span><br><span class="line">.map(<span class="type">YarnSparkHadoopUtil</span>.escapeForShell)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">sparkConf.get(<span class="type">AM_LIBRARY_PATH</span>).foreach &#123; paths =&gt;</span><br><span class="line"></span><br><span class="line">prefixEnv = <span class="type">Some</span>(createLibraryPathPrefix(paths, sparkConf))</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// For log4j2 configuration to reference</span></span><br><span class="line"></span><br><span class="line">javaOpts += (<span class="string">&quot;-Dspark.yarn.app.container.log.dir=&quot;</span> + <span class="type">ApplicationConstants</span>.<span class="type">LOG_DIR_EXPANSION_VAR</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> userClass =</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (isClusterMode) &#123;</span><br><span class="line"></span><br><span class="line"><span class="type">Seq</span>(<span class="string">&quot;--class&quot;</span>, <span class="type">YarnSparkHadoopUtil</span>.escapeForShell(args.userClass))</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="type">Nil</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> userJar =</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (args.userJar != <span class="literal">null</span>) &#123;</span><br><span class="line"></span><br><span class="line"><span class="type">Seq</span>(<span class="string">&quot;--jar&quot;</span>, args.userJar)</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="type">Nil</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> primaryPyFile =</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (isClusterMode &amp;&amp; args.primaryPyFile != <span class="literal">null</span>) &#123;</span><br><span class="line"></span><br><span class="line"><span class="type">Seq</span>(<span class="string">&quot;--primary-py-file&quot;</span>, <span class="keyword">new</span> <span class="type">Path</span>(args.primaryPyFile).getName())</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="type">Nil</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> primaryRFile =</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (args.primaryRFile != <span class="literal">null</span>) &#123;</span><br><span class="line"></span><br><span class="line"><span class="type">Seq</span>(<span class="string">&quot;--primary-r-file&quot;</span>, args.primaryRFile)</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="type">Nil</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> amClass =</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (isClusterMode) &#123;</span><br><span class="line"></span><br><span class="line"><span class="type">Utils</span>.classForName(<span class="string">&quot;org.apache.spark.deploy.yarn.ApplicationMaster&quot;</span>).getName</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="type">Utils</span>.classForName(<span class="string">&quot;org.apache.spark.deploy.yarn.ExecutorLauncher&quot;</span>).getName</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (args.primaryRFile != <span class="literal">null</span> &amp;&amp;</span><br><span class="line"></span><br><span class="line">(args.primaryRFile.endsWith(<span class="string">&quot;.R&quot;</span>) || args.primaryRFile.endsWith(<span class="string">&quot;.r&quot;</span>))) &#123;</span><br><span class="line"></span><br><span class="line">args.userArgs = <span class="type">ArrayBuffer</span>(args.primaryRFile) ++ args.userArgs</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> userArgs = args.userArgs.flatMap &#123; arg =&gt;</span><br><span class="line"></span><br><span class="line"><span class="type">Seq</span>(<span class="string">&quot;--arg&quot;</span>, <span class="type">YarnSparkHadoopUtil</span>.escapeForShell(arg))</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> amArgs =</span><br><span class="line"></span><br><span class="line"><span class="type">Seq</span>(amClass) ++ userClass ++ userJar ++ primaryPyFile ++ primaryRFile ++ userArgs ++</span><br><span class="line"></span><br><span class="line"><span class="type">Seq</span>(<span class="string">&quot;--properties-file&quot;</span>,</span><br><span class="line"></span><br><span class="line">buildPath(<span class="type">Environment</span>.<span class="type">PWD</span>.$$(), <span class="type">LOCALIZED_CONF_DIR</span>, <span class="type">SPARK_CONF_FILE</span>)) ++</span><br><span class="line"></span><br><span class="line"><span class="type">Seq</span>(<span class="string">&quot;--dist-cache-conf&quot;</span>,</span><br><span class="line"></span><br><span class="line">buildPath(<span class="type">Environment</span>.<span class="type">PWD</span>.$$(), <span class="type">LOCALIZED_CONF_DIR</span>, <span class="type">DIST_CACHE_CONF_FILE</span>))</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">// Command for the ApplicationMaster</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> commands = prefixEnv ++</span><br><span class="line"></span><br><span class="line"><span class="type">Seq</span>(<span class="type">Environment</span>.<span class="type">JAVA_HOME</span>.$$() + <span class="string">&quot;/bin/java&quot;</span>, <span class="string">&quot;-server&quot;</span>) ++</span><br><span class="line"></span><br><span class="line">javaOpts ++ amArgs ++</span><br><span class="line"></span><br><span class="line"><span class="type">Seq</span>(</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;1&gt;&quot;</span>, <span class="type">ApplicationConstants</span>.<span class="type">LOG_DIR_EXPANSION_VAR</span> + <span class="string">&quot;/stdout&quot;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;2&gt;&quot;</span>, <span class="type">ApplicationConstants</span>.<span class="type">LOG_DIR_EXPANSION_VAR</span> + <span class="string">&quot;/stderr&quot;</span>)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">// <span class="doctag">TODO:</span> it would be nicer to just make sure there are no null commands here</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> printableCommands = commands.map(s =&gt; <span class="keyword">if</span> (s == <span class="literal">null</span>) <span class="string">&quot;null&quot;</span> <span class="keyword">else</span> s).toList</span><br><span class="line"></span><br><span class="line">amContainer.setCommands(printableCommands.asJava)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">// send the acl settings into YARN to control who has access via YARN interfaces</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> securityManager = <span class="keyword">new</span> <span class="type">SecurityManager</span>(sparkConf)</span><br><span class="line"></span><br><span class="line">amContainer.setApplicationACLs(</span><br><span class="line"></span><br><span class="line"><span class="type">YarnSparkHadoopUtil</span>.getApplicationAclsForYarn(securityManager).asJava)</span><br><span class="line"></span><br><span class="line">setupSecurityToken(amContainer)</span><br><span class="line"></span><br><span class="line">setTokenConf(amContainer)</span><br><span class="line"></span><br><span class="line">amContainer</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们看一下这段代码，他其实也是在构建启动的命令。我们重点关注下这几句代码</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">val</span> userClass =</span><br><span class="line"><span class="keyword">if</span> (isClusterMode) &#123;</span><br><span class="line">	<span class="type">Seq</span>(<span class="string">&quot;--class&quot;</span>, <span class="type">YarnSparkHadoopUtil</span>.escapeForShell(args.userClass))</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">	<span class="type">Nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> amClass =</span><br><span class="line"><span class="keyword">if</span> (isClusterMode) &#123;</span><br><span class="line">	<span class="type">Utils</span>.classForName(<span class="string">&quot;org.apache.spark.deploy.yarn.ApplicationMaster&quot;</span>).getName</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">	<span class="type">Utils</span>.classForName(<span class="string">&quot;org.apache.spark.deploy.yarn.ExecutorLauncher&quot;</span>).getName</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>userClass 用户真实要启动的类，在cluster模式下，从参数中解析。<br>amClass 启动类，在cluster模式下，为<code>ApplicationMaster</code>. 在我们的这个例子中，就会在Yarn中启动一个Application，启动类为<code>ApplicationMaster</code>. 接下来我们要看<code>ApplicationMaster</code>这个类的代码。<br>还有一点要注意一下，以上所有的代码都是在本地执行的，也就是在执行submit-shell脚本的这个机器上执行的。后续的操作都是在Yarn集群上执行的</p>
<h2 id="ApplicationMaster"><a href="#ApplicationMaster" class="headerlink" title="ApplicationMaster"></a>ApplicationMaster</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">	<span class="type">SignalUtils</span>.registerLogger(log)</span><br><span class="line">	<span class="keyword">val</span> amArgs = <span class="keyword">new</span> <span class="type">ApplicationMasterArguments</span>(args)</span><br><span class="line">	<span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">	<span class="keyword">if</span> (amArgs.propertiesFile != <span class="literal">null</span>) &#123;</span><br><span class="line">		<span class="type">Utils</span>.getPropertiesFromFile(amArgs.propertiesFile).foreach &#123; <span class="keyword">case</span> (k, v) =&gt;</span><br><span class="line">		sparkConf.set(k, v)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Both cases create a new SparkConf object which reads these configs from system properties.</span></span><br><span class="line">	sparkConf.getAll.foreach &#123; <span class="keyword">case</span> (k, v) =&gt;</span><br><span class="line">		sys.props(k) = v</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">val</span> yarnConf = <span class="keyword">new</span> <span class="type">YarnConfiguration</span>(<span class="type">SparkHadoopUtil</span>.newConfiguration(sparkConf))</span><br><span class="line">	master = <span class="keyword">new</span> <span class="type">ApplicationMaster</span>(amArgs, sparkConf, yarnConf)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">val</span> ugi = sparkConf.get(<span class="type">PRINCIPAL</span>) <span class="keyword">match</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> <span class="type">Some</span>(principal) <span class="keyword">if</span> master.isClusterMode =&gt;</span><br><span class="line">		<span class="keyword">val</span> originalCreds = <span class="type">UserGroupInformation</span>.getCurrentUser().getCredentials()</span><br><span class="line">		<span class="type">SparkHadoopUtil</span>.get.loginUserFromKeytab(principal, sparkConf.get(<span class="type">KEYTAB</span>).orNull)</span><br><span class="line">		<span class="keyword">val</span> newUGI = <span class="type">UserGroupInformation</span>.getCurrentUser()</span><br><span class="line">		<span class="keyword">if</span> (master.appAttemptId == <span class="literal">null</span> || master.appAttemptId.getAttemptId &gt; <span class="number">1</span>) &#123;</span><br><span class="line">			<span class="type">Utils</span>.withContextClassLoader(master.userClassLoader) &#123;</span><br><span class="line">			<span class="keyword">val</span> credentialManager = <span class="keyword">new</span> <span class="type">HadoopDelegationTokenManager</span>(sparkConf, yarnConf, <span class="literal">null</span>)</span><br><span class="line">			credentialManager.obtainDelegationTokens(originalCreds)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">		newUGI.addCredentials(originalCreds)</span><br><span class="line">		newUGI</span><br><span class="line">	<span class="keyword">case</span> _ =&gt;</span><br><span class="line">		<span class="type">SparkHadoopUtil</span>.get.createSparkUser()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ugi.doAs(<span class="keyword">new</span> <span class="type">PrivilegedExceptionAction</span>[<span class="type">Unit</span>]() &#123;</span><br><span class="line">	<span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = <span class="type">System</span>.exit(master.run())</span><br><span class="line">	&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码的主要逻辑为构建<code>ApplicationMaster</code>并调用其<code>run</code>方法。根据其返回值做响应。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Int</span> = &#123;</span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		<span class="keyword">val</span> attemptID = <span class="keyword">if</span> (isClusterMode) &#123;</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			<span class="type">None</span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">new</span> <span class="type">CallerContext</span>(<span class="string">&quot;APPMASTER&quot;</span>, sparkConf.get(<span class="type">APP_CALLER_CONTEXT</span>),</span><br><span class="line">			<span class="type">Option</span>(appAttemptId.getApplicationId.toString), attemptID).setCurrentContext()</span><br><span class="line">		</span><br><span class="line">		logInfo(<span class="string">&quot;ApplicationAttemptId: &quot;</span> + appAttemptId)</span><br><span class="line">		<span class="keyword">val</span> stagingDirPath = <span class="keyword">new</span> <span class="type">Path</span>(<span class="type">System</span>.getenv(<span class="string">&quot;SPARK_YARN_STAGING_DIR&quot;</span>))</span><br><span class="line">		<span class="keyword">val</span> stagingDirFs = stagingDirPath.getFileSystem(yarnConf)</span><br><span class="line">		<span class="keyword">val</span> priority = <span class="type">ShutdownHookManager</span>.<span class="type">SPARK_CONTEXT_SHUTDOWN_PRIORITY</span> - <span class="number">1</span></span><br><span class="line">		<span class="type">ShutdownHookManager</span>.addShutdownHook(priority) &#123; () =&gt;</span><br><span class="line">			...</span><br><span class="line">		&#125;</span><br><span class="line">	</span><br><span class="line">		<span class="keyword">if</span> (isClusterMode) &#123;</span><br><span class="line">			runDriver()</span><br><span class="line">		&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">			runExecutorLauncher()</span><br><span class="line">		&#125;</span><br><span class="line">	&#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</span><br><span class="line">		logError(<span class="string">&quot;Uncaught exception: &quot;</span>, e)</span><br><span class="line">		finish(<span class="type">FinalApplicationStatus</span>.<span class="type">FAILEDApplicationMaster</span>.<span class="type">EXIT_UNCAUGHT_EXCEPTION</span>,<span class="string">&quot;Uncaught exception: &quot;</span> + <span class="type">StringUtils</span>.stringifyException(e))</span><br><span class="line">	&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">		<span class="keyword">try</span> &#123;</span><br><span class="line">			metricsSystem.foreach &#123; ms =&gt;</span><br><span class="line">				ms.report()</span><br><span class="line">				ms.stop()</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</span><br><span class="line">		logWarning(<span class="string">&quot;Exception during stopping of the metric system: &quot;</span>, e)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	exitCode</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">runDriver</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">addAmIpFilter(<span class="type">None</span>, <span class="type">System</span>.getenv(<span class="type">ApplicationConstants</span>.<span class="type">APPLICATION_WEB_PROXY_BASE_ENV</span>))</span><br><span class="line"></span><br><span class="line">userClassThread = startUserApplication()</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="comment">// This a bit hacky, but we need to wait until the spark.driver.port property has</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// been set by the Thread executing the user class.</span></span><br><span class="line"></span><br><span class="line">logInfo(<span class="string">&quot;Waiting for spark context initialization...&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> totalWaitTime = sparkConf.get(<span class="type">AM_MAX_WAIT_TIME</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> sc = <span class="type">ThreadUtils</span>.awaitResult(sparkContextPromise.future,</span><br><span class="line"></span><br><span class="line"><span class="type">Duration</span>(totalWaitTime, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (sc != <span class="literal">null</span>) &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> rpcEnv = sc.env.rpcEnv</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> userConf = sc.getConf</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> host = userConf.get(<span class="type">DRIVER_HOST_ADDRESS</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> port = userConf.get(<span class="type">DRIVER_PORT</span>)</span><br><span class="line"></span><br><span class="line">registerAM(host, port, userConf, sc.ui.map(_.webUrl), appAttemptId)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> driverRef = rpcEnv.setupEndpointRef(</span><br><span class="line"></span><br><span class="line"><span class="type">RpcAddress</span>(host, port),</span><br><span class="line"></span><br><span class="line"><span class="type">YarnSchedulerBackend</span>.<span class="type">ENDPOINT_NAME</span>)</span><br><span class="line"></span><br><span class="line">createAllocator(driverRef, userConf, rpcEnv, appAttemptId, distCacheConf)</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Sanity check; should never happen in normal operation, since sc should only be null</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// if the user app did not create a SparkContext.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(<span class="string">&quot;User did not initialize spark context!&quot;</span>)</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resumeDriver()</span><br><span class="line"></span><br><span class="line">userClassThread.join()</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">catch</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> e: <span class="type">SparkException</span> <span class="keyword">if</span> e.getCause().isInstanceOf[<span class="type">TimeoutException</span>] =&gt;</span><br><span class="line"></span><br><span class="line">logError(</span><br><span class="line"></span><br><span class="line"><span class="string">s&quot;SparkContext did not initialize after waiting for <span class="subst">$totalWaitTime</span> ms. &quot;</span> +</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;Please check earlier log output for errors. Failing the application.&quot;</span>)</span><br><span class="line"></span><br><span class="line">finish(<span class="type">FinalApplicationStatus</span>.<span class="type">FAILED</span>,</span><br><span class="line"></span><br><span class="line"><span class="type">ApplicationMaster</span>.<span class="type">EXIT_SC_NOT_INITED</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;Timed out waiting for SparkContext.&quot;</span>)</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line"></span><br><span class="line">resumeDriver()</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">startUserApplication</span></span>(): <span class="type">Thread</span> = &#123;  </span><br><span class="line">logInfo(<span class="string">&quot;Starting the user application in a separate Thread&quot;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">var</span> userArgs = args.userArgs  </span><br><span class="line"><span class="keyword">if</span> (args.primaryPyFile != <span class="literal">null</span> &amp;&amp; args.primaryPyFile.endsWith(<span class="string">&quot;.py&quot;</span>)) &#123;  </span><br><span class="line"><span class="comment">// When running pyspark, the app is run using PythonRunner. The second argument is the list  </span></span><br><span class="line"><span class="comment">// of files to add to PYTHONPATH, which Client.scala already handles, so it&#x27;s empty.  </span></span><br><span class="line">userArgs = <span class="type">Seq</span>(args.primaryPyFile, <span class="string">&quot;&quot;</span>) ++ userArgs  </span><br><span class="line">&#125;  </span><br><span class="line"><span class="keyword">if</span> (args.primaryRFile != <span class="literal">null</span> &amp;&amp;  </span><br><span class="line">(args.primaryRFile.endsWith(<span class="string">&quot;.R&quot;</span>) || args.primaryRFile.endsWith(<span class="string">&quot;.r&quot;</span>))) &#123;  </span><br><span class="line"><span class="comment">// TODO(davies): add R dependencies here  </span></span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">val</span> mainMethod = userClassLoader.loadClass(args.userClass)  </span><br><span class="line">.getMethod(<span class="string">&quot;main&quot;</span>, classOf[<span class="type">Array</span>[<span class="type">String</span>]])  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">val</span> userThread = <span class="keyword">new</span> <span class="type">Thread</span> &#123;  </span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = &#123;  </span><br><span class="line"><span class="keyword">try</span> &#123;  </span><br><span class="line"><span class="keyword">if</span> (!<span class="type">Modifier</span>.isStatic(mainMethod.getModifiers)) &#123;  </span><br><span class="line">logError(<span class="string">s&quot;Could not find static main method in object <span class="subst">$&#123;args.userClass&#125;</span>&quot;</span>)  </span><br><span class="line">finish(<span class="type">FinalApplicationStatus</span>.<span class="type">FAILED</span>, <span class="type">ApplicationMaster</span>.<span class="type">EXIT_EXCEPTION_USER_CLASS</span>)  </span><br><span class="line">&#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">mainMethod.invoke(<span class="literal">null</span>, userArgs.toArray)  </span><br><span class="line">finish(<span class="type">FinalApplicationStatus</span>.<span class="type">SUCCEEDED</span>, <span class="type">ApplicationMaster</span>.<span class="type">EXIT_SUCCESS</span>)  </span><br><span class="line">logDebug(<span class="string">&quot;Done running user class&quot;</span>)  </span><br><span class="line">&#125;  </span><br><span class="line">&#125; <span class="keyword">catch</span> &#123;  </span><br><span class="line"><span class="keyword">case</span> e: <span class="type">InvocationTargetException</span> =&gt;  </span><br><span class="line">e.getCause <span class="keyword">match</span> &#123;  </span><br><span class="line"><span class="keyword">case</span> _: <span class="type">InterruptedException</span> =&gt;  </span><br><span class="line"><span class="comment">// Reporter thread can interrupt to stop user class  </span></span><br><span class="line"><span class="keyword">case</span> <span class="type">SparkUserAppException</span>(exitCode) =&gt;  </span><br><span class="line"><span class="keyword">val</span> msg = <span class="string">s&quot;User application exited with status <span class="subst">$exitCode</span>&quot;</span>  </span><br><span class="line">logError(msg)  </span><br><span class="line">finish(<span class="type">FinalApplicationStatus</span>.<span class="type">FAILED</span>, exitCode, msg)  </span><br><span class="line"><span class="keyword">case</span> cause: <span class="type">Throwable</span> =&gt;  </span><br><span class="line">logError(<span class="string">&quot;User class threw exception: &quot;</span>, cause)  </span><br><span class="line">finish(<span class="type">FinalApplicationStatus</span>.<span class="type">FAILED</span>,  </span><br><span class="line"><span class="type">ApplicationMaster</span>.<span class="type">EXIT_EXCEPTION_USER_CLASS</span>,  </span><br><span class="line"><span class="string">&quot;User class threw exception: &quot;</span> + <span class="type">StringUtils</span>.stringifyException(cause))  </span><br><span class="line">&#125;  </span><br><span class="line">sparkContextPromise.tryFailure(e.getCause())  </span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;  </span><br><span class="line"><span class="comment">// Notify the thread waiting for the SparkContext, in case the application did not  </span></span><br><span class="line"><span class="comment">// instantiate one. This will do nothing when the user code instantiates a SparkContext  </span></span><br><span class="line"><span class="comment">// (with the correct master), or when the user code throws an exception (due to the  </span></span><br><span class="line"><span class="comment">// tryFailure above).  </span></span><br><span class="line">sparkContextPromise.trySuccess(<span class="literal">null</span>)  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;  </span><br><span class="line">&#125;  </span><br><span class="line">userThread.setContextClassLoader(userClassLoader)  </span><br><span class="line">userThread.setName(<span class="string">&quot;Driver&quot;</span>)  </span><br><span class="line">userThread.start()  </span><br><span class="line">userThread  </span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>在<code>ApplicationMaster</code>的<code>run</code>方法中，我们可以看到它做了这样几件事：构建上下文，添加钩子函数， 在我们这个例子中调用<code>runDriver</code>方法。<br>在<code>runDriver</code>方法中，我们可以看到上面就会调用<code>startUserApplication</code>这个方法，从这个函数名称我们也可以看到，这里才真正调用到了用户程序，使用反射调用到了用户的程序，在用户的程序中会做SparkContext的初始化，如果用户的主程序没有做SparkContext的初始化，在<code>runDriver</code>中也会进行检测，从而抛出异常。用户程序是新启动一个线程来运行，主程序会等待用户程序结束。</p>
<h2 id="JavaWordCount"><a href="#JavaWordCount" class="headerlink" title="JavaWordCount"></a>JavaWordCount</h2><p>我们再来看下我们的这个example程序。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> (args.length &lt; <span class="number">1</span>) &#123;  </span><br><span class="line">System.err.println(<span class="string">&quot;Usage: JavaWordCount &lt;file&gt;&quot;</span>);  </span><br><span class="line">System.exit(<span class="number">1</span>);  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession  </span><br><span class="line">.builder()  </span><br><span class="line">.appName(<span class="string">&quot;JavaWordCount&quot;</span>)  </span><br><span class="line">.getOrCreate();  </span><br><span class="line">  </span><br><span class="line">JavaRDD&lt;String&gt; lines = spark.read().textFile(args[<span class="number">0</span>]).javaRDD();  </span><br><span class="line">  </span><br><span class="line">JavaRDD&lt;String&gt; words = lines.flatMap(s -&gt; Arrays.asList(SPACE.split(s)).iterator());  </span><br><span class="line">  </span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; ones = words.mapToPair(s -&gt; <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(s, <span class="number">1</span>));  </span><br><span class="line">  </span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; counts = ones.reduceByKey((i1, i2) -&gt; i1 + i2);  </span><br><span class="line">  </span><br><span class="line">List&lt;Tuple2&lt;String, Integer&gt;&gt; output = counts.collect();  </span><br><span class="line"><span class="keyword">for</span> (Tuple2&lt;?,?&gt; tuple : output) &#123;  </span><br><span class="line">System.out.println(tuple._1() + <span class="string">&quot;: &quot;</span> + tuple._2());  </span><br><span class="line">&#125;  </span><br><span class="line">spark.stop();  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在这里初始化了SparkSession，然后从文件读取，转化，然后调用<code>collect</code>算子后打印结果。<br>最终关闭SparkSession。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collect</span></span>(): <span class="type">Array</span>[<span class="type">T</span>] = withScope &#123;  </span><br><span class="line"><span class="keyword">val</span> results = sc.runJob(<span class="keyword">this</span>, (iter: <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; iter.toArray)  </span><br><span class="line"><span class="type">Array</span>.concat(results: _*)  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在这个例子中，是最后的collect这个action算子，最终调用了<code>runJob</code>。<br>到这里就完成了整个任务的部署。</p>
<p>总结一下：<br>当我们执行<code>spark-submit.sh</code>时，会先执行<code>SparkSubmit</code>然后根据<code>master</code>和<code>deploy-mode</code>启动不同的提交类。如果是local mode则直接启动用户的主类，否则启动不同集群模式的类。<br>在集群提交类中，此例中为<code>YarnClusterApplication</code>. 在这个类中做的事情是在Yarn集群上启动一个Application也就是<code>ApplicationMaster</code>，这个Application启动后会在一个新线程启动user application。user application也就是我们任务的主类。</p>
<h1 id="SparkLauncher"><a href="#SparkLauncher" class="headerlink" title="SparkLauncher"></a>SparkLauncher</h1><p>Spark还提供了一种方式，可以将提交任务集成到Java代码中。用户可以使用一个Service来集中化做任务提交，可以方便的管理集群中提交的任务数量等等。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">SparkLauncher</span> <span class="variable">launcher</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkLauncher</span>();</span><br><span class="line">launcher.setMaster(“yarn”);</span><br><span class="line">launcher.setDeployMode(“cluster”);</span><br><span class="line">launcher.setMainClass(“...”);</span><br><span class="line">launcher.setAppResource(“...”);</span><br><span class="line">launcher.addAppArgs(“...”);</span><br><span class="line">...</span><br><span class="line">SparkAppHandle.<span class="type">Listener</span> <span class="variable">listener</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkAppHandle</span>.Listener()&#123;...&#125;</span><br><span class="line">launcher.startApplication(listener);</span><br></pre></td></tr></table></figure>
<p>我们可以以一个大概这样的代码就可以提交并启动一个Spark任务。并且添加了Listener，可以对任务的状态进行感知。<br>我们来看一下这个的具体实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> SparkAppHandle <span class="title function_">startApplication</span><span class="params">(SparkAppHandle.Listener... listeners)</span> <span class="keyword">throws</span> IOException &#123;  </span><br><span class="line"><span class="type">LauncherServer</span> <span class="variable">server</span> <span class="operator">=</span> LauncherServer.getOrCreateServer();  </span><br><span class="line"><span class="type">ChildProcAppHandle</span> <span class="variable">handle</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ChildProcAppHandle</span>(server);  </span><br><span class="line"><span class="keyword">for</span> (SparkAppHandle.Listener l : listeners) &#123;  </span><br><span class="line">handle.addListener(l);  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="type">String</span> <span class="variable">secret</span> <span class="operator">=</span> server.registerHandle(handle);  </span><br><span class="line">  </span><br><span class="line"><span class="type">String</span> <span class="variable">loggerName</span> <span class="operator">=</span> getLoggerName();  </span><br><span class="line"><span class="type">ProcessBuilder</span> <span class="variable">pb</span> <span class="operator">=</span> createBuilder();  </span><br><span class="line"><span class="keyword">if</span> (LOG.isLoggable(Level.FINE)) &#123;  </span><br><span class="line">LOG.fine(String.format(<span class="string">&quot;Launching Spark application:%n%s&quot;</span>, join(<span class="string">&quot; &quot;</span>, pb.command())));  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="type">boolean</span> <span class="variable">outputToLog</span> <span class="operator">=</span> outputStream == <span class="literal">null</span>;  </span><br><span class="line"><span class="type">boolean</span> <span class="variable">errorToLog</span> <span class="operator">=</span> !redirectErrorStream &amp;&amp; errorStream == <span class="literal">null</span>;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">// Only setup stderr + stdout to logger redirection if user has not otherwise configured output  </span></span><br><span class="line"><span class="comment">// redirection.  </span></span><br><span class="line"><span class="keyword">if</span> (loggerName == <span class="literal">null</span> &amp;&amp; (outputToLog || errorToLog)) &#123;  </span><br><span class="line">String appName;  </span><br><span class="line"><span class="keyword">if</span> (builder.appName != <span class="literal">null</span>) &#123;  </span><br><span class="line">appName = builder.appName;  </span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (builder.mainClass != <span class="literal">null</span>) &#123;  </span><br><span class="line"><span class="type">int</span> <span class="variable">dot</span> <span class="operator">=</span> builder.mainClass.lastIndexOf(<span class="string">&quot;.&quot;</span>);  </span><br><span class="line"><span class="keyword">if</span> (dot &gt;= <span class="number">0</span> &amp;&amp; dot &lt; builder.mainClass.length() - <span class="number">1</span>) &#123;  </span><br><span class="line">appName = builder.mainClass.substring(dot + <span class="number">1</span>, builder.mainClass.length());  </span><br><span class="line">&#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">appName = builder.mainClass;  </span><br><span class="line">&#125;  </span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (builder.appResource != <span class="literal">null</span>) &#123;  </span><br><span class="line">appName = <span class="keyword">new</span> <span class="title class_">File</span>(builder.appResource).getName();  </span><br><span class="line">&#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">appName = String.valueOf(COUNTER.incrementAndGet());  </span><br><span class="line">&#125;  </span><br><span class="line"><span class="type">String</span> <span class="variable">loggerPrefix</span> <span class="operator">=</span> getClass().getPackage().getName();  </span><br><span class="line">loggerName = String.format(<span class="string">&quot;%s.app.%s&quot;</span>, loggerPrefix, appName);  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> (outputToLog &amp;&amp; errorToLog) &#123;  </span><br><span class="line">pb.redirectErrorStream(<span class="literal">true</span>);  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">pb.environment().put(LauncherProtocol.ENV_LAUNCHER_PORT, String.valueOf(server.getPort()));  </span><br><span class="line">pb.environment().put(LauncherProtocol.ENV_LAUNCHER_SECRET, secret);  </span><br><span class="line"><span class="keyword">try</span> &#123;  </span><br><span class="line"><span class="type">Process</span> <span class="variable">child</span> <span class="operator">=</span> pb.start();  </span><br><span class="line"><span class="type">InputStream</span> <span class="variable">logStream</span> <span class="operator">=</span> <span class="literal">null</span>;  </span><br><span class="line"><span class="keyword">if</span> (loggerName != <span class="literal">null</span>) &#123;  </span><br><span class="line">logStream = outputToLog ? child.getInputStream() : child.getErrorStream();  </span><br><span class="line">&#125;  </span><br><span class="line">handle.setChildProc(child, loggerName, logStream);  </span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException ioe) &#123;  </span><br><span class="line">handle.kill();  </span><br><span class="line"><span class="keyword">throw</span> ioe;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">return</span> handle;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码中的主要逻辑是调用了<code>ProcessBuilder.start()</code>方法，我们先看一下这个<code>ProcessBuilder</code>创建逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> ProcessBuilder <span class="title function_">createBuilder</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;  </span><br><span class="line">List&lt;String&gt; cmd = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();  </span><br><span class="line">cmd.add(findSparkSubmit());  </span><br><span class="line">cmd.addAll(builder.buildSparkSubmitArgs());  </span><br><span class="line">  </span><br><span class="line"><span class="comment">// Since the child process is a batch script, let&#x27;s quote things so that special characters are  </span></span><br><span class="line"><span class="comment">// preserved, otherwise the batch interpreter will mess up the arguments. Batch scripts are  </span></span><br><span class="line"><span class="comment">// weird.  </span></span><br><span class="line"><span class="keyword">if</span> (isWindows()) &#123;  </span><br><span class="line">List&lt;String&gt; winCmd = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();  </span><br><span class="line"><span class="keyword">for</span> (String arg : cmd) &#123;  </span><br><span class="line">winCmd.add(quoteForBatchScript(arg));  </span><br><span class="line">&#125;  </span><br><span class="line">cmd = winCmd;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="type">ProcessBuilder</span> <span class="variable">pb</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ProcessBuilder</span>(cmd.toArray(<span class="keyword">new</span> <span class="title class_">String</span>[cmd.size()]));  </span><br><span class="line"><span class="keyword">for</span> (Map.Entry&lt;String, String&gt; e : builder.childEnv.entrySet()) &#123;  </span><br><span class="line">pb.environment().put(e.getKey(), e.getValue());  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> (workingDir != <span class="literal">null</span>) &#123;  </span><br><span class="line">pb.directory(workingDir);  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">// Only one of redirectError and redirectError(...) can be specified.  </span></span><br><span class="line"><span class="comment">// Similarly, if redirectToLog is specified, no other redirections should be specified.  </span></span><br><span class="line">checkState(!redirectErrorStream || errorStream == <span class="literal">null</span>,  </span><br><span class="line"><span class="string">&quot;Cannot specify both redirectError() and redirectError(...) &quot;</span>);  </span><br><span class="line">checkState(getLoggerName() == <span class="literal">null</span> ||  </span><br><span class="line">((!redirectErrorStream &amp;&amp; errorStream == <span class="literal">null</span>) || outputStream == <span class="literal">null</span>),  </span><br><span class="line"><span class="string">&quot;Cannot used redirectToLog() in conjunction with other redirection methods.&quot;</span>);  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> (redirectErrorStream) &#123;  </span><br><span class="line">pb.redirectErrorStream(<span class="literal">true</span>);  </span><br><span class="line">&#125;  </span><br><span class="line"><span class="keyword">if</span> (errorStream != <span class="literal">null</span>) &#123;  </span><br><span class="line">pb.redirectError(errorStream);  </span><br><span class="line">&#125;  </span><br><span class="line"><span class="keyword">if</span> (outputStream != <span class="literal">null</span>) &#123;  </span><br><span class="line">pb.redirectOutput(outputStream);  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">return</span> pb;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过这段代码可以看出它其实也是在构建一段<code>spark-submit</code>命令。<br>通过<code>ProcessBuilder</code>构建并运行<code>spark-submit</code>命令，然后将其作为子进程进行监控。</p>

<br>
<h2>Tags: </h2>
  <p><a class="classtest-link" href="/tags/big-data-spark/" rel="tag">big_data/spark</a> — 2023年7月22日</p>
  

  <script async src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
  });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

  <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
<script>
  $(document).ready(() => {
    const maraidConfig = {
      theme: "default",
      logLevel: 3,
      flowchart: { curve: "linear" },
      gantt: { axisFormat: "%m/%d/%Y" },
      sequence: { actorMargin: 50 },
    };
    mermaid.initialize(maraidConfig);
  });
</script>

        </div>
        <!-- <div class="row mt-2">
  <h3>Search</h3>
  <div><input id="search-text" title="search" class="search-text" type="text" placeholder="search......"></div>
  <div style="margin-top: 1.5rem;">
    <ul id="result"></ul>
  </div>
</div> -->
        <div class="row mt-2">
  
    <div class="eight columns">
      <p id="madewith">Made with ❤ and
        <a class="footer-link icon" href="https://hexo.io" target="_blank" style="text-decoration: none;" rel="noreferrer" aria-label="Hexo.io">
        <svg class="hexo svg-hov" width="14" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><title>Hexo.js</title><path d="M12 .007L1.57 6.056V18.05L12 23.995l10.43-6.049V5.952L12 .007zm4.798 17.105l-.939.521-.939-.521V12.94H9.08v4.172l-.94.521-.938-.521V6.89l.939-.521.939.521v4.172h5.84V6.89l.94-.521.938.521v10.222z"/></svg>
        </a>
        
    </div>

    <!-- Sepcial thanks to https://simpleicons.org/ for the icons -->
    <div class="four columns mb-3 posisi" >
      
      <a class="ml-0 footer-link icon" href="https://github.com/liunaijie" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="GitHub">
        <svg class="github svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      </a>
      

      

      

      

      
      
        <a class="ml-0 footer-link icon" href="mailto:jarvis@apache.org" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="Email">
          <svg class="email svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Email</title><path d="M12 12.713l11.985-7.99c-.01-.01-11.985-7.723-11.985-7.723s-11.975 7.713-11.985 7.723l11.985 7.99zm0 2.287l-12-8v14h24v-14l-12 8z"/></svg>
        </a>
        
    </div>
  
</div>

      </div>

    </div>

  </div>
  <script src="/js/nanobar.min.js"></script>

  <script>
    var options = {
      classname: 'nanobar',
      id: 'myNanobar'
    };
    var nanobar = new Nanobar(options);
    nanobar.go(30);
    nanobar.go(76);
    nanobar.go(100);
  </script>

</body>

</html>