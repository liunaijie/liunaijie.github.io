<!DOCTYPE html>
<html lang="zh-CN">

<head>

  <!-- Minima -->
  <!-- Hexo theme created by @adisaktijrs -->

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">

  
  <title>Spark源码解析-(二)SparkContext</title>
  
  <link rel="canonical" href="https://www.liunaijie.top/2023/07/29/Blog-Posts/publish/Spark%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-(%E4%BA%8C)SparkContext/">
  
  <meta name="description" content="继上一篇分析完Spark的提交流程之后, 这次继续分析下SparkContext的源码. 创建当Spark通过反射调用用户提交类的主函数时, 用户的主函数内会完成SparkContext的创建.还是以JavaWordCount为例 123456789101112131415public static">
  
  
  <meta name="keywords" content="blog">
  
  <meta name="author" content="Jarvis">
  
  
  
  <meta property="og:site_name" content="J.A.R.V.I.S" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="Spark源码解析-(二)SparkContext" />
  
  <meta property="og:description" content="继上一篇分析完Spark的提交流程之后, 这次继续分析下SparkContext的源码. 创建当Spark通过反射调用用户提交类的主函数时, 用户的主函数内会完成SparkContext的创建.还是以JavaWordCount为例 123456789101112131415public static">
  
  <meta property="og:url" content="https://www.liunaijie.top/2023/07/29/Blog-Posts/publish/Spark%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-(%E4%BA%8C)SparkContext/" />

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Spark源码解析-(二)SparkContext">
  
  <meta name="twitter:description" content="继上一篇分析完Spark的提交流程之后, 这次继续分析下SparkContext的源码. 创建当Spark通过反射调用用户提交类的主函数时, 用户的主函数内会完成SparkContext的创建.还是以JavaWordCount为例 123456789101112131415public static">
  
  
  
  
  <meta name="twitter:url" content="https://www.liunaijie.top/2023/07/29/Blog-Posts/publish/Spark%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-(%E4%BA%8C)SparkContext/" />

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Preload fonts
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="preload" href="/fonts/dm-serif-display-v4-latin-regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="/fonts/inter-v2-latin-regular.woff2" as="font" type="font/woff2" crossorigin>

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  
<link rel="stylesheet" href="/css/normalize.css">

  
<link rel="stylesheet" href="/css/skeleton.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
<link rel="stylesheet" href="/css/prism-dark.css">

  
<link rel="stylesheet" href="/css/prism-line-numbers.css">

  <!-- User css -->
  

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="/images/jarvis.png">

  <!-- Custom Theme Color Style
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <style>
  a:not(.icon) {
    text-decoration-color: #0FA0CE;
    background-image: linear-gradient(
      to bottom,
      rgba(0, 0, 0, 0) 50%,
      #0FA0CE 50%
    );
  }
  blockquote {
    border-left: 8px solid #0FA0CE;
  }
  .nanobar .bar {
    background: #0FA0CE;
  }
  .button.button-primary:hover,
  button.button-primary:hover,
  input[type="submit"].button-primary:hover,
  input[type="reset"].button-primary:hover,
  input[type="button"].button-primary:hover,
  .button.button-primary:focus,
  button.button-primary:focus,
  input[type="submit"].button-primary:focus,
  input[type="reset"].button-primary:focus,
  input[type="button"].button-primary:focus {
    background-color: #0FA0CE;
    border-color: #0FA0CE;
  }
  input[type="email"]:focus,
  input[type="number"]:focus,
  input[type="search"]:focus,
  input[type="text"]:focus,
  input[type="tel"]:focus,
  input[type="url"]:focus,
  input[type="password"]:focus,
  textarea:focus,
  select:focus {
    border: 1px solid #0FA0CE;
  }
</style>

  <!-- Google Analytics (With Privacy Settings On)
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  

  
  <script src="/js/pic.min.js" defer></script>
  

  

<meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="J.A.R.V.I.S" type="application/atom+xml">
</head>

<body>
  <div class="container">
    <div class="row">
      <div>

        <div class="row">
  <div class="two columns" style="max-width: 50px">
    <h1 class="mt-2 mode">
      <div onclick=setDarkMode(true) id="darkBtn"></div>
      <div onclick=setDarkMode(false) id="lightBtn" class=hidden></div>
      <script >
        if (localStorage.getItem('preferredTheme') == 'dark') {
          setDarkMode(true)
        }
        function setDarkMode(isDark) {
          var darkBtn = document.getElementById('darkBtn')
          var lightBtn = document.getElementById('lightBtn')
          if (isDark) {
            lightBtn.style.display = "block"
            darkBtn.style.display = "none"
            localStorage.setItem('preferredTheme', 'dark');
          } else {
            lightBtn.style.display = "none"
            darkBtn.style.display = "block"
            localStorage.removeItem('preferredTheme');
          }
          document.body.classList.toggle("darkmode");
        }
      </script>
    </h1>
  </div>

  <div class="six columns ml-1">
    <h1 class="mt-2">
      Jarvis&#39;s Blog
    </h1>
  </div>

  <div class="twelve columns">
    <div class="row">
      <div class="nine columns left">
        
          
          <a href="/" class="ml">Home</a>
          
        
          
          <a href="/categories/publish/" class="ml">Publish</a>
          
        
          
          <a href="/about" class="ml">About</a>
          
        
          
          <a href="/atom.xml" class="ml">Rss</a>
          
        
      </div>
    </div>
    <hr style="margin-bottom: 2.6rem">
  </div>
</div>

        <div class="trans">
            <h2>Spark源码解析-(二)SparkContext</h2>

  <p>继上一篇分析完Spark的提交流程之后, 这次继续分析下SparkContext的源码.</p>
<h1 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h1><p>当Spark通过反射调用用户提交类的主函数时, 用户的主函数内会完成SparkContext的创建.<br>还是以<code>JavaWordCount</code>为例</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;  </span><br><span class="line">  ...</span><br><span class="line">  <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession  </span><br><span class="line">    .builder()  </span><br><span class="line">    .appName(<span class="string">&quot;JavaWordCount&quot;</span>)  </span><br><span class="line">    .getOrCreate();  </span><br><span class="line">  </span><br><span class="line">  JavaRDD&lt;String&gt; lines = spark.read().textFile(args[<span class="number">0</span>]).javaRDD();  </span><br><span class="line">	...  </span><br><span class="line">  List&lt;Tuple2&lt;String, Integer&gt;&gt; output = counts.collect();  </span><br><span class="line">  <span class="keyword">for</span> (Tuple2&lt;?,?&gt; tuple : output) &#123;  </span><br><span class="line">    System.out.println(tuple._1() + <span class="string">&quot;: &quot;</span> + tuple._2());  </span><br><span class="line">  &#125;  </span><br><span class="line">  spark.stop();  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在这里是手动创建了SparkSession, SparkContext由SparkSession间接完成创建.</p>
<h1 id="主要代码分析"><a href="#主要代码分析" class="headerlink" title="主要代码分析"></a>主要代码分析</h1><p><code>SparkContext</code>维护了<code>DAGScheduler</code>和<code>TaskScheduler</code>, 在创建<code>SparkContext</code>时会完成这两个类的创建及初始化.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;  </span><br><span class="line">  _conf = config.clone()  </span><br><span class="line">  _conf.validateSettings()  </span><br><span class="line">  _conf.set(<span class="string">&quot;spark.app.startTime&quot;</span>, startTime.toString)  </span><br><span class="line">  ...   </span><br><span class="line">  </span><br><span class="line">  _listenerBus = <span class="keyword">new</span> <span class="title class_">LiveListenerBus</span>(_conf)  </span><br><span class="line">  _resourceProfileManager = <span class="keyword">new</span> <span class="title class_">ResourceProfileManager</span>(_conf, _listenerBus)  </span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Initialize the app status store and listener before SparkEnv is created so that it gets  </span></span><br><span class="line">  <span class="comment">// all events.  val appStatusSource = AppStatusSource.createSource(conf)  </span></span><br><span class="line">  _statusStore = AppStatusStore.createLiveStore(conf, appStatusSource)  </span><br><span class="line">  listenerBus.addToStatusQueue(_statusStore.listener.get)  </span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Create the Spark execution environment (cache, map output tracker, etc)  </span></span><br><span class="line">  _env = createSparkEnv(_conf, isLocal, listenerBus)  </span><br><span class="line">  SparkEnv.set(_env)  </span><br><span class="line">  ...</span><br><span class="line">  _statusTracker = <span class="keyword">new</span> <span class="title class_">SparkStatusTracker</span>(<span class="built_in">this</span>, _statusStore)  </span><br><span class="line">  </span><br><span class="line">  _progressBar =  </span><br><span class="line">    <span class="keyword">if</span> (_conf.get(UI_SHOW_CONSOLE_PROGRESS)) &#123;  </span><br><span class="line">      Some(<span class="keyword">new</span> <span class="title class_">ConsoleProgressBar</span>(<span class="built_in">this</span>))  </span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">      None  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">  _ui =  </span><br><span class="line">    <span class="keyword">if</span> (conf.get(UI_ENABLED)) &#123;  </span><br><span class="line">      Some(SparkUI.create(Some(<span class="built_in">this</span>), _statusStore, _conf, _env.securityManager, appName, <span class="string">&quot;&quot;</span>,  </span><br><span class="line">        startTime))  </span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">      <span class="comment">// For tests, do not enable the UI  </span></span><br><span class="line">      None  </span><br><span class="line">    &#125;  </span><br><span class="line">	...</span><br><span class="line">  _hadoopConfiguration = SparkHadoopUtil.get.newConfiguration(_conf)  </span><br><span class="line">    ...</span><br><span class="line">  _executorMemory = SparkContext.executorMemoryInMb(_conf)  </span><br><span class="line">   ...</span><br><span class="line">  _shuffleDriverComponents = ShuffleDataIOUtils.loadShuffleDataIO(config).driver()  </span><br><span class="line">  _shuffleDriverComponents.initializeApplication().asScala.foreach &#123; <span class="keyword">case</span> (k, v) =&gt;  </span><br><span class="line">    _conf.set(ShuffleDataIOUtils.SHUFFLE_SPARK_CONF_PREFIX + k, v)  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="comment">// We need to register &quot;HeartbeatReceiver&quot; before &quot;createTaskScheduler&quot; because Executor will  </span></span><br><span class="line">  <span class="comment">// retrieve &quot;HeartbeatReceiver&quot; in the constructor. (SPARK-6640)  _heartbeatReceiver = env.rpcEnv.setupEndpoint(  </span></span><br><span class="line">    HeartbeatReceiver.ENDPOINT_NAME, <span class="keyword">new</span> <span class="title class_">HeartbeatReceiver</span>(<span class="built_in">this</span>))  </span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Initialize any plugins before the task scheduler is initialized.  </span></span><br><span class="line">  _plugins = PluginContainer(<span class="built_in">this</span>, _resources.asJava)  </span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Create and start the scheduler  </span></span><br><span class="line">  val (sched, ts) = SparkContext.createTaskScheduler(<span class="built_in">this</span>, master)  </span><br><span class="line">  _schedulerBackend = <span class="type">sched</span>  </span><br><span class="line">  <span class="variable">_taskScheduler</span> <span class="operator">=</span> <span class="type">ts</span>  </span><br><span class="line">  <span class="variable">_dagScheduler</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DAGScheduler</span>(<span class="built_in">this</span>)  </span><br><span class="line">  _heartbeatReceiver.ask[Boolean](TaskSchedulerIsSet)  </span><br><span class="line">  </span><br><span class="line">  <span class="type">val</span> <span class="variable">_executorMetricsSource</span> <span class="operator">=</span>  </span><br><span class="line">    <span class="keyword">if</span> (_conf.get(METRICS_EXECUTORMETRICS_SOURCE_ENABLED)) &#123;  </span><br><span class="line">      Some(<span class="keyword">new</span> <span class="title class_">ExecutorMetricsSource</span>)  </span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">      None  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="comment">// create and start the heartbeater for collecting memory metrics  </span></span><br><span class="line">  _heartbeater = <span class="keyword">new</span> <span class="title class_">Heartbeater</span>(  </span><br><span class="line">    () =&gt; SparkContext.<span class="built_in">this</span>.reportHeartBeat(_executorMetricsSource),  </span><br><span class="line">    <span class="string">&quot;driver-heartbeater&quot;</span>,  </span><br><span class="line">    conf.get(EXECUTOR_HEARTBEAT_INTERVAL))  </span><br><span class="line">  _heartbeater.start()  </span><br><span class="line">  </span><br><span class="line">  <span class="comment">// start TaskScheduler after taskScheduler sets DAGScheduler reference in DAGScheduler&#x27;s  </span></span><br><span class="line">  <span class="comment">// constructor  _taskScheduler.start()  </span></span><br><span class="line">  </span><br><span class="line">  _applicationId = _taskScheduler.applicationId()  </span><br><span class="line">  _applicationAttemptId = _taskScheduler.applicationAttemptId()  </span><br><span class="line">  _conf.set(<span class="string">&quot;spark.app.id&quot;</span>, _applicationId)  </span><br><span class="line">  _applicationAttemptId.foreach &#123; attemptId =&gt;  </span><br><span class="line">    _conf.set(APP_ATTEMPT_ID, attemptId)  </span><br><span class="line">    _env.blockManager.blockStoreClient.setAppAttemptId(attemptId)  </span><br><span class="line">  &#125;  </span><br><span class="line">  <span class="keyword">if</span> (_conf.get(UI_REVERSE_PROXY)) &#123;  </span><br><span class="line">    <span class="type">val</span> <span class="variable">proxyUrl</span> <span class="operator">=</span> _conf.get(UI_REVERSE_PROXY_URL).getOrElse(<span class="string">&quot;&quot;</span>).stripSuffix(<span class="string">&quot;/&quot;</span>)  </span><br><span class="line">    System.setProperty(<span class="string">&quot;spark.ui.proxyBase&quot;</span>, proxyUrl + <span class="string">&quot;/proxy/&quot;</span> + _applicationId)  </span><br><span class="line">  &#125;  </span><br><span class="line">  _ui.foreach(_.setAppId(_applicationId))  </span><br><span class="line">  _env.blockManager.initialize(_applicationId)  </span><br><span class="line">  FallbackStorage.registerBlockManagerIfNeeded(_env.blockManager.master, _conf)  </span><br><span class="line">   </span><br><span class="line">  ...  </span><br><span class="line">  </span><br><span class="line">  _cleaner =  </span><br><span class="line">    <span class="keyword">if</span> (_conf.get(CLEANER_REFERENCE_TRACKING)) &#123;  </span><br><span class="line">      Some(<span class="keyword">new</span> <span class="title class_">ContextCleaner</span>(<span class="built_in">this</span>, _shuffleDriverComponents))  </span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">      None  </span><br><span class="line">    &#125;  </span><br><span class="line">  _cleaner.foreach(_.start())  </span><br><span class="line">  </span><br><span class="line">  <span class="type">val</span> <span class="variable">dynamicAllocationEnabled</span> <span class="operator">=</span> Utils.isDynamicAllocationEnabled(_conf)  </span><br><span class="line">  _executorAllocationManager =  </span><br><span class="line">    <span class="keyword">if</span> (dynamicAllocationEnabled) &#123;  </span><br><span class="line">      schedulerBackend match &#123;  </span><br><span class="line">        <span class="keyword">case</span> b: ExecutorAllocationClient =&gt;  </span><br><span class="line">          Some(<span class="keyword">new</span> <span class="title class_">ExecutorAllocationManager</span>(  </span><br><span class="line">            schedulerBackend.asInstanceOf[ExecutorAllocationClient], listenerBus, _conf,  </span><br><span class="line">            cleaner = cleaner, resourceProfileManager = resourceProfileManager))  </span><br><span class="line">        <span class="type">case</span> <span class="variable">_</span> <span class="operator">=</span>&gt;  </span><br><span class="line">          None  </span><br><span class="line">      &#125;  </span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">      None  </span><br><span class="line">    &#125;  </span><br><span class="line">  _executorAllocationManager.foreach(_.start())  </span><br><span class="line">  </span><br><span class="line">  setupAndStartListenerBus()  </span><br><span class="line">  postEnvironmentUpdate()  </span><br><span class="line">  postApplicationStart()  </span><br><span class="line">  </span><br><span class="line">  <span class="comment">// After application started, attach handlers to started server and start handler.  </span></span><br><span class="line">  _ui.foreach(_.attachAllHandler())  </span><br><span class="line">  <span class="comment">// Attach the driver metrics servlet handler to the web ui after the metrics system is started.  </span></span><br><span class="line">  _env.metricsSystem.getServletHandlers.foreach(handler =&gt; ui.foreach(_.attachHandler(handler)))  </span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Make sure the context is stopped if the user forgets about it. This avoids leaving  </span></span><br><span class="line">  <span class="comment">// unfinished event logs around after the JVM exits cleanly. It doesn&#x27;t help if the JVM  // is killed, though.  logDebug(&quot;Adding shutdown hook&quot;) // force eager creation of logger  </span></span><br><span class="line">  _shutdownHookRef = ShutdownHookManager.addShutdownHook(  </span><br><span class="line">    ShutdownHookManager.SPARK_CONTEXT_SHUTDOWN_PRIORITY) &#123; () =&gt;  </span><br><span class="line">    logInfo(<span class="string">&quot;Invoking stop() from shutdown hook&quot;</span>)  </span><br><span class="line">    <span class="keyword">try</span> &#123;  </span><br><span class="line">      stop()  </span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;  </span><br><span class="line">      <span class="keyword">case</span> e: Throwable =&gt;  </span><br><span class="line">        logWarning(<span class="string">&quot;Ignoring Exception while stopping SparkContext from shutdown hook&quot;</span>, e)  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Post init  </span></span><br><span class="line">  _taskScheduler.postStartHook()  </span><br><span class="line">  <span class="keyword">if</span> (isLocal) &#123;  </span><br><span class="line">    _env.metricsSystem.registerSource(Executor.executorSourceLocalModeOnly)  </span><br><span class="line">  &#125;  </span><br><span class="line">  _env.metricsSystem.registerSource(_dagScheduler.metricsSource)  </span><br><span class="line">  _env.metricsSystem.registerSource(<span class="keyword">new</span> <span class="title class_">BlockManagerSource</span>(_env.blockManager))  </span><br><span class="line">  _env.metricsSystem.registerSource(<span class="keyword">new</span> <span class="title class_">JVMCPUSource</span>())  </span><br><span class="line">  _executorMetricsSource.foreach(_.register(_env.metricsSystem))  </span><br><span class="line">  _executorAllocationManager.foreach &#123; e =&gt;  </span><br><span class="line">    _env.metricsSystem.registerSource(e.executorAllocationManagerSource)  </span><br><span class="line">  &#125;  </span><br><span class="line">  appStatusSource.foreach(_env.metricsSystem.registerSource(_))  </span><br><span class="line">  _plugins.foreach(_.registerMetrics(applicationId))  </span><br><span class="line">&#125; <span class="keyword">catch</span> &#123;  </span><br><span class="line">	...  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过<code>SparkContext.createTaskScheduler(this, master)</code>创建了<code>SchedulerBackend</code>与<code>TaskScheduler</code>. 之后又创建了<code>DAGScheduler</code>.<br>先来看<code>TaskScheduler</code>的创建过程:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> def <span class="title function_">createTaskScheduler</span><span class="params">(  </span></span><br><span class="line"><span class="params">    sc: SparkContext,  </span></span><br><span class="line"><span class="params">    master: String)</span>: (SchedulerBackend, TaskScheduler) = &#123;  </span><br><span class="line">  <span class="keyword">import</span> SparkMasterRegex._  </span><br><span class="line">   ...</span><br><span class="line">  master match &#123;  </span><br><span class="line">    <span class="keyword">case</span> <span class="string">&quot;local&quot;</span> =&gt;  </span><br><span class="line">      checkResourcesPerTask(<span class="number">1</span>)  </span><br><span class="line">      <span class="type">val</span> <span class="variable">scheduler</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskSchedulerImpl</span>(sc, MAX_LOCAL_TASK_FAILURES, isLocal = <span class="literal">true</span>)  </span><br><span class="line">      <span class="type">val</span> <span class="variable">backend</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">LocalSchedulerBackend</span>(sc.getConf, scheduler, <span class="number">1</span>)  </span><br><span class="line">      scheduler.initialize(backend)  </span><br><span class="line">      (backend, scheduler)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">case</span> <span class="title function_">LOCAL_N_REGEX</span><span class="params">(threads)</span> =&gt;  </span><br><span class="line">      def localCpuCount: Int = Runtime.getRuntime.availableProcessors()  </span><br><span class="line">      <span class="comment">// local[*] estimates the number of cores on the machine; local[N] uses exactly N threads.  </span></span><br><span class="line">      <span class="type">val</span> <span class="variable">threadCount</span> <span class="operator">=</span> <span class="keyword">if</span> (threads == <span class="string">&quot;*&quot;</span>) localCpuCount <span class="keyword">else</span> threads.toInt  </span><br><span class="line">      <span class="title function_">if</span> <span class="params">(threadCount &lt;= <span class="number">0</span>)</span> &#123;  </span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">SparkException</span>(s<span class="string">&quot;Asked to run locally with $threadCount threads&quot;</span>)  </span><br><span class="line">      &#125;  </span><br><span class="line">      checkResourcesPerTask(threadCount)  </span><br><span class="line">      <span class="type">val</span> <span class="variable">scheduler</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskSchedulerImpl</span>(sc, MAX_LOCAL_TASK_FAILURES, isLocal = <span class="literal">true</span>)  </span><br><span class="line">      <span class="type">val</span> <span class="variable">backend</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">LocalSchedulerBackend</span>(sc.getConf, scheduler, threadCount)  </span><br><span class="line">      scheduler.initialize(backend)  </span><br><span class="line">      (backend, scheduler)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">case</span> <span class="title function_">LOCAL_N_FAILURES_REGEX</span><span class="params">(threads, maxFailures)</span> =&gt;  </span><br><span class="line">      def localCpuCount: Int = Runtime.getRuntime.availableProcessors()  </span><br><span class="line">      <span class="comment">// local[*, M] means the number of cores on the computer with M failures  </span></span><br><span class="line">      <span class="comment">// local[N, M] means exactly N threads with M failures      val threadCount = if (threads == &quot;*&quot;) localCpuCount else threads.toInt  </span></span><br><span class="line">      checkResourcesPerTask(threadCount)  </span><br><span class="line">      <span class="type">val</span> <span class="variable">scheduler</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskSchedulerImpl</span>(sc, maxFailures.toInt, isLocal = <span class="literal">true</span>)  </span><br><span class="line">      <span class="type">val</span> <span class="variable">backend</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">LocalSchedulerBackend</span>(sc.getConf, scheduler, threadCount)  </span><br><span class="line">      scheduler.initialize(backend)  </span><br><span class="line">      (backend, scheduler)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">case</span> <span class="title function_">SPARK_REGEX</span><span class="params">(sparkUrl)</span> =&gt;  </span><br><span class="line">      <span class="type">val</span> <span class="variable">scheduler</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskSchedulerImpl</span>(sc)  </span><br><span class="line">      <span class="type">val</span> <span class="variable">masterUrls</span> <span class="operator">=</span> sparkUrl.split(<span class="string">&quot;,&quot;</span>).map(<span class="string">&quot;spark://&quot;</span> + _)  </span><br><span class="line">      <span class="type">val</span> <span class="variable">backend</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StandaloneSchedulerBackend</span>(scheduler, sc, masterUrls)  </span><br><span class="line">      scheduler.initialize(backend)  </span><br><span class="line">      (backend, scheduler)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">case</span> <span class="title function_">LOCAL_CLUSTER_REGEX</span><span class="params">(numWorkers, coresPerWorker, memoryPerWorker)</span> =&gt;  </span><br><span class="line">      checkResourcesPerTask(coresPerWorker.toInt)  </span><br><span class="line">      <span class="comment">// Check to make sure memory requested &lt;= memoryPerWorker. Otherwise Spark will just hang.  </span></span><br><span class="line">      <span class="type">val</span> <span class="variable">memoryPerWorkerInt</span> <span class="operator">=</span> memoryPerWorker.toInt  </span><br><span class="line">      <span class="title function_">if</span> <span class="params">(sc.executorMemory &gt; memoryPerWorkerInt)</span> &#123;  </span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">SparkException</span>(  </span><br><span class="line">          <span class="string">&quot;Asked to launch cluster with %d MiB/worker but requested %d MiB/executor&quot;</span>.format(  </span><br><span class="line">            memoryPerWorkerInt, sc.executorMemory))  </span><br><span class="line">      &#125;  </span><br><span class="line">  </span><br><span class="line">      <span class="comment">// For host local mode setting the default of SHUFFLE_HOST_LOCAL_DISK_READING_ENABLED  </span></span><br><span class="line">      <span class="comment">// to false because this mode is intended to be used for testing and in this case all the      // executors are running on the same host. So if host local reading was enabled here then      // testing of the remote fetching would be secondary as setting this config explicitly to      // false would be required in most of the unit test (despite the fact that remote fetching      // is much more frequent in production).   </span></span><br><span class="line">	  sc.conf.setIfMissing(SHUFFLE_HOST_LOCAL_DISK_READING_ENABLED, <span class="literal">false</span>)  </span><br><span class="line">  </span><br><span class="line">      <span class="type">val</span> <span class="variable">scheduler</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TaskSchedulerImpl</span>(sc)  </span><br><span class="line">      <span class="type">val</span> <span class="variable">localCluster</span> <span class="operator">=</span> LocalSparkCluster(  </span><br><span class="line">        numWorkers.toInt, coresPerWorker.toInt, memoryPerWorkerInt, sc.conf)  </span><br><span class="line">      <span class="type">val</span> <span class="variable">masterUrls</span> <span class="operator">=</span> localCluster.start()  </span><br><span class="line">      <span class="type">val</span> <span class="variable">backend</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StandaloneSchedulerBackend</span>(scheduler, sc, masterUrls)  </span><br><span class="line">      scheduler.initialize(backend)  </span><br><span class="line">      backend.shutdownCallback = (backend: StandaloneSchedulerBackend) =&gt; &#123;  </span><br><span class="line">        localCluster.stop()  </span><br><span class="line">      &#125;  </span><br><span class="line">      (backend, scheduler)  </span><br><span class="line">  </span><br><span class="line">    <span class="type">case</span> <span class="variable">masterUrl</span> <span class="operator">=</span>&gt;  </span><br><span class="line">      <span class="type">val</span> <span class="variable">cm</span> <span class="operator">=</span> getClusterManager(masterUrl) match &#123;  </span><br><span class="line">        <span class="keyword">case</span> <span class="title function_">Some</span><span class="params">(clusterMgr)</span> =&gt; clusterMgr  </span><br><span class="line">        <span class="type">case</span> <span class="variable">None</span> <span class="operator">=</span>&gt; <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">SparkException</span>(<span class="string">&quot;Could not parse Master URL: &#x27;&quot;</span> + master + <span class="string">&quot;&#x27;&quot;</span>)  </span><br><span class="line">      &#125;  </span><br><span class="line">      <span class="keyword">try</span> &#123;  </span><br><span class="line">        <span class="type">val</span> <span class="variable">scheduler</span> <span class="operator">=</span> cm.createTaskScheduler(sc, masterUrl)  </span><br><span class="line">        <span class="type">val</span> <span class="variable">backend</span> <span class="operator">=</span> cm.createSchedulerBackend(sc, masterUrl, scheduler)  </span><br><span class="line">        cm.initialize(scheduler, backend)  </span><br><span class="line">        (backend, scheduler)  </span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;  </span><br><span class="line">        <span class="keyword">case</span> se: SparkException =&gt; <span class="keyword">throw</span> se  </span><br><span class="line">        <span class="keyword">case</span> <span class="title function_">NonFatal</span><span class="params">(e)</span> =&gt;  </span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">SparkException</span>(<span class="string">&quot;External scheduler cannot be instantiated&quot;</span>, e)  </span><br><span class="line">      &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里其实是对我们任务提交类型的判断, 从而选择不同的实现类.<br>而后续的<code>DAGScheduler</code>创建, 传入了<code>SparkContext</code>与<code>TaskScheduler</code>参数, 在DAGScheduler内部做了<code>TaskScheduler</code>与<code>DAGScheduler</code>的绑定<br><code>taskScheduler.setDAGScheduler(this)</code><br>SparkContext初始化时, 相当于完成了基础的准备工作. </p>
<p>后续当用户的action算子触发计算时, 会调用<code>dagScheduler</code>来做任务的划分与分配.<br> 在<code>JavaWordCount</code>这个例子中, 当调用<code>collect</code>算子时, 最终会调用到<code>SparkContext</code>类中的<code>runJob</code>方法. </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">def runJob[T, U: ClassTag](  </span><br><span class="line">    rdd: RDD[T],  </span><br><span class="line">    func: (TaskContext, Iterator[T]) =&gt; U,  </span><br><span class="line">    partitions: Seq[Int],  </span><br><span class="line">    resultHandler: (Int, U) =&gt; Unit): Unit = &#123;  </span><br><span class="line">  <span class="keyword">if</span> (stopped.get()) &#123;  </span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalStateException</span>(<span class="string">&quot;SparkContext has been shutdown&quot;</span>)  </span><br><span class="line">  &#125;  </span><br><span class="line">  <span class="type">val</span> <span class="variable">callSite</span> <span class="operator">=</span> getCallSite  </span><br><span class="line">  <span class="type">val</span> <span class="variable">cleanedFunc</span> <span class="operator">=</span> clean(func)  </span><br><span class="line">  logInfo(<span class="string">&quot;Starting job: &quot;</span> + callSite.shortForm)  </span><br><span class="line">  <span class="keyword">if</span> (conf.getBoolean(<span class="string">&quot;spark.logLineage&quot;</span>, <span class="literal">false</span>)) &#123;  </span><br><span class="line">    logInfo(<span class="string">&quot;RDD&#x27;s recursive dependencies:\n&quot;</span> + rdd.toDebugString)  </span><br><span class="line">  &#125;  </span><br><span class="line">  dagScheduler.runJob(rdd, cleanedFunc, partitions, callSite, resultHandler, localProperties.get)  </span><br><span class="line">  progressBar.foreach(_.finishAll())  </span><br><span class="line">  rdd.doCheckpoint()  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="DAGScheduler"><a href="#DAGScheduler" class="headerlink" title="DAGScheduler"></a>DAGScheduler</h2><p>通过上面的代码可以知道, 这里调用了<code>dagScheduler</code>来提交任务.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">def runJob[T, U](  </span><br><span class="line">    rdd: RDD[T],  </span><br><span class="line">    func: (TaskContext, Iterator[T]) =&gt; U,  </span><br><span class="line">    partitions: Seq[Int],  </span><br><span class="line">    callSite: CallSite,  </span><br><span class="line">    resultHandler: (Int, U) =&gt; Unit,  </span><br><span class="line">    properties: Properties): Unit = &#123;  </span><br><span class="line">  <span class="type">val</span> <span class="variable">start</span> <span class="operator">=</span> System.nanoTime  </span><br><span class="line">  <span class="type">val</span> <span class="variable">waiter</span> <span class="operator">=</span> submitJob(rdd, func, partitions, callSite, resultHandler, properties)  </span><br><span class="line">  ThreadUtils.awaitReady(waiter.completionFuture, Duration.Inf)  </span><br><span class="line">  waiter.completionFuture.value.get match &#123;  </span><br><span class="line">    <span class="keyword">case</span> scala.util.Success(_) =&gt;  </span><br><span class="line">      logInfo(<span class="string">&quot;Job %d finished: %s, took %f s&quot;</span>.format  </span><br><span class="line">        (waiter.jobId, callSite.shortForm, (System.nanoTime - start) / <span class="number">1e9</span>))  </span><br><span class="line">    <span class="keyword">case</span> scala.util.Failure(exception) =&gt;  </span><br><span class="line">      logInfo(<span class="string">&quot;Job %d failed: %s, took %f s&quot;</span>.format  </span><br><span class="line">        (waiter.jobId, callSite.shortForm, (System.nanoTime - start) / <span class="number">1e9</span>))  </span><br><span class="line">      <span class="comment">// SPARK-8644: Include user stack trace in exceptions coming from DAGScheduler.  </span></span><br><span class="line">      <span class="type">val</span> <span class="variable">callerStackTrace</span> <span class="operator">=</span> Thread.currentThread().getStackTrace.tail  </span><br><span class="line">      exception.setStackTrace(exception.getStackTrace ++ callerStackTrace)  </span><br><span class="line">      <span class="keyword">throw</span> exception  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在<code>DAGScheduler</code>里又调用了<code>submitJob</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def submitJob[T, U](  </span><br><span class="line">    rdd: RDD[T],  </span><br><span class="line">    func: (TaskContext, Iterator[T]) =&gt; U,  </span><br><span class="line">    partitions: Seq[Int],  </span><br><span class="line">    callSite: CallSite,  </span><br><span class="line">    resultHandler: (Int, U) =&gt; Unit,  </span><br><span class="line">    properties: Properties): JobWaiter[U] = &#123;  </span><br><span class="line">  ...</span><br><span class="line">  <span class="type">val</span> <span class="variable">jobId</span> <span class="operator">=</span> nextJobId.getAndIncrement()  </span><br><span class="line">  ...  </span><br><span class="line">  <span class="type">val</span> <span class="variable">func2</span> <span class="operator">=</span> func.asInstanceOf[(TaskContext, Iterator[_]) =&gt; _]  </span><br><span class="line">  <span class="type">val</span> <span class="variable">waiter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JobWaiter</span>[U](<span class="built_in">this</span>, jobId, partitions.size, resultHandler)  </span><br><span class="line">  eventProcessLoop.post(JobSubmitted(  </span><br><span class="line">    jobId, rdd, func2, partitions.toArray, callSite, waiter,  </span><br><span class="line">    Utils.cloneProperties(properties)))  </span><br><span class="line">  waiter  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>向<code>eventProcessLoop</code>发送了<code>JobSubmitted</code>的消息, 消息内包含了任务的基础信息.<br><strong>这里的调用采用了消息传递, 而不是直接的方法调用.</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> def <span class="title function_">doOnReceive</span><span class="params">(event: DAGSchedulerEvent)</span>: Unit = event match &#123;  </span><br><span class="line">  <span class="keyword">case</span> <span class="title function_">JobSubmitted</span><span class="params">(jobId, rdd, func, partitions, callSite, listener, properties)</span> =&gt;  </span><br><span class="line">    dagScheduler.handleJobSubmitted(jobId, rdd, func, partitions, callSite, listener, properties)</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当<code>DagScheduler</code>收到消息后, 做模式匹配, 我们上面提交的<code>JobSubmitter</code>消息会调用<code>handleJobSubmitter</code>方法来处理.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[scheduler] def <span class="title function_">handleJobSubmitted</span><span class="params">(jobId: Int,  </span></span><br><span class="line"><span class="params">    finalRDD: RDD[_],  </span></span><br><span class="line"><span class="params">    func: (TaskContext, Iterator[_])</span> =&gt; _,  </span><br><span class="line">    partitions: Array[Int],  </span><br><span class="line">    callSite: CallSite,  </span><br><span class="line">    listener: JobListener,  </span><br><span class="line">    properties: Properties): Unit = &#123;  </span><br><span class="line">  <span class="keyword">var</span> finalStage: ResultStage = <span class="literal">null</span>  </span><br><span class="line">  <span class="keyword">try</span> &#123;  </span><br><span class="line">    <span class="comment">// New stage creation may throw an exception if, for example, jobs are run on a  </span></span><br><span class="line">    <span class="comment">// HadoopRDD whose underlying HDFS files have been deleted.    </span></span><br><span class="line">    finalStage = createResultStage(finalRDD, func, partitions, jobId, callSite)  </span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;  </span><br><span class="line">    ...  </span><br><span class="line">  &#125;  </span><br><span class="line">  <span class="comment">// Job submitted, clear internal data.  </span></span><br><span class="line">  barrierJobIdToNumTasksCheckFailures.remove(jobId)  </span><br><span class="line">  </span><br><span class="line">  <span class="type">val</span> <span class="variable">job</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ActiveJob</span>(jobId, finalStage, callSite, listener, properties)  </span><br><span class="line">  clearCacheLocs()  </span><br><span class="line">  ...</span><br><span class="line">  <span class="type">val</span> <span class="variable">jobSubmissionTime</span> <span class="operator">=</span> clock.getTimeMillis()  </span><br><span class="line">  jobIdToActiveJob(jobId) = job  </span><br><span class="line">  activeJobs += job  </span><br><span class="line">  finalStage.setActiveJob(job)  </span><br><span class="line">  <span class="type">val</span> <span class="variable">stageIds</span> <span class="operator">=</span> jobIdToStageIds(jobId).toArray  </span><br><span class="line">  <span class="type">val</span> <span class="variable">stageInfos</span> <span class="operator">=</span> stageIds.flatMap(id =&gt; stageIdToStage.get(id).map(_.latestInfo))  </span><br><span class="line">  listenerBus.post(  </span><br><span class="line">    SparkListenerJobStart(job.jobId, jobSubmissionTime, stageInfos,  </span><br><span class="line">      Utils.cloneProperties(properties)))  </span><br><span class="line">  submitStage(finalStage)  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>根据传入的RDD获取最后一步的<code>Stage</code>信息, 最后调用<code>submitStage</code>方法.<br>先来看下如何获取的<code>finalStage</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> def <span class="title function_">createResultStage</span><span class="params">(  </span></span><br><span class="line"><span class="params">    rdd: RDD[_],  </span></span><br><span class="line"><span class="params">    func: (TaskContext, Iterator[_])</span> =&gt; _,  </span><br><span class="line">    partitions: Array[Int],  </span><br><span class="line">    jobId: Int,  </span><br><span class="line">    callSite: CallSite): ResultStage = &#123;  </span><br><span class="line">  val (shuffleDeps, resourceProfiles) = getShuffleDependenciesAndResourceProfiles(rdd)  </span><br><span class="line">  <span class="type">val</span> <span class="variable">resourceProfile</span> <span class="operator">=</span> mergeResourceProfilesForStage(resourceProfiles)  </span><br><span class="line">  checkBarrierStageWithDynamicAllocation(rdd)  </span><br><span class="line">  checkBarrierStageWithNumSlots(rdd, resourceProfile)  </span><br><span class="line">  checkBarrierStageWithRDDChainPattern(rdd, partitions.toSet.size)  </span><br><span class="line">  <span class="type">val</span> <span class="variable">parents</span> <span class="operator">=</span> getOrCreateParentStages(shuffleDeps, jobId)  </span><br><span class="line">  <span class="type">val</span> <span class="variable">id</span> <span class="operator">=</span> nextStageId.getAndIncrement()  </span><br><span class="line">  <span class="type">val</span> <span class="variable">stage</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ResultStage</span>(id, rdd, func, partitions, parents, jobId,  </span><br><span class="line">    callSite, resourceProfile.id)  </span><br><span class="line">  stageIdToStage(id) = stage  </span><br><span class="line">  <span class="title function_">updateJobIdStageIdMaps</span><span class="params">(jobId, stage)</span>  </span><br><span class="line">  stage  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其实我们知道Spark里根据是否需要做Shuffle来划分Stage, 那么这里就会根据一个RDD的所有依赖做划分, 这个切分就是在这里根据RDD的dependency信息做的.<br>当切分完成后, 会创建一个<code>ResultStage</code>表示这是最后一个<code>Stage</code>. 这个<code>Stage</code>里会有一个<code>parents</code>的Stage信息.</p>
<p>我们再来看下<code>submitStage</code>的代码部分</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> def <span class="title function_">submitStage</span><span class="params">(stage: Stage)</span>: Unit = &#123;  </span><br><span class="line">  <span class="type">val</span> <span class="variable">jobId</span> <span class="operator">=</span> activeJobForStage(stage)  </span><br><span class="line">  <span class="keyword">if</span> (jobId.isDefined) &#123;  </span><br><span class="line">    logDebug(s<span class="string">&quot;submitStage($stage (name=$&#123;stage.name&#125;;&quot;</span> +  </span><br><span class="line">      s<span class="string">&quot;jobs=$&#123;stage.jobIds.toSeq.sorted.mkString(&quot;</span>,<span class="string">&quot;)&#125;))&quot;</span>)  </span><br><span class="line">    <span class="keyword">if</span> (!waitingStages(stage) &amp;&amp; !runningStages(stage) &amp;&amp; !failedStages(stage)) &#123;  </span><br><span class="line">      <span class="type">val</span> <span class="variable">missing</span> <span class="operator">=</span> getMissingParentStages(stage).sortBy(_.id)  </span><br><span class="line">      logDebug(<span class="string">&quot;missing: &quot;</span> + missing)  </span><br><span class="line">      <span class="keyword">if</span> (missing.isEmpty) &#123;  </span><br><span class="line">        logInfo(<span class="string">&quot;Submitting &quot;</span> + stage + <span class="string">&quot; (&quot;</span> + stage.rdd + <span class="string">&quot;), which has no missing parents&quot;</span>)  </span><br><span class="line">        submitMissingTasks(stage, jobId.get)  </span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">        <span class="keyword">for</span> (parent &lt;- missing) &#123;  </span><br><span class="line">          submitStage(parent)  </span><br><span class="line">        &#125;  </span><br><span class="line">        waitingStages += stage  </span><br><span class="line">      &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">    abortStage(stage, <span class="string">&quot;No active job for stage &quot;</span> + stage.id, None)  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当收到<code>finialStage</code>后, 可以看到做的事情是先获取<code>Parent Stage</code>. 当<code>Parent Stage</code>为空时才会提交自身的Stage, 不然会先计算<code>Parent Stage</code>.<br><code>Stage</code>是有依赖关系的, 所有当计算最后一个Stage时需要先完成之前所有Stage的计算.<br>注意当有上游依赖时, 循环提交完成后还向 <code>waitingStages</code>添加了自身的<code>Stage</code>. </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> def <span class="title function_">submitMissingTasks</span><span class="params">(stage: Stage, jobId: Int)</span>: Unit = &#123;  </span><br><span class="line">  logDebug(<span class="string">&quot;submitMissingTasks(&quot;</span> + stage + <span class="string">&quot;)&quot;</span>)  </span><br><span class="line">  ...  </span><br><span class="line">  <span class="comment">// Figure out the indexes of partition ids to compute.  </span></span><br><span class="line">  val partitionsToCompute: Seq[Int] = stage.findMissingPartitions()  </span><br><span class="line">  ...</span><br><span class="line">  runningStages += stage  </span><br><span class="line">  <span class="comment">// SparkListenerStageSubmitted should be posted before testing whether tasks are  </span></span><br><span class="line">  <span class="comment">// serializable. If tasks are not serializable, a SparkListenerStageCompleted event  // will be posted, which should always come after a corresponding SparkListenerStageSubmitted  // event.  </span></span><br><span class="line">  stage match &#123;  </span><br><span class="line">    <span class="keyword">case</span> s: ShuffleMapStage =&gt;  </span><br><span class="line">      outputCommitCoordinator.stageStart(stage = s.id, maxPartitionId = s.numPartitions - <span class="number">1</span>)  </span><br><span class="line">      <span class="comment">// Only generate merger location for a given shuffle dependency once.  </span></span><br><span class="line">      <span class="keyword">if</span> (s.shuffleDep.shuffleMergeAllowed) &#123;  </span><br><span class="line">        <span class="keyword">if</span> (!s.shuffleDep.isShuffleMergeFinalizedMarked) &#123;  </span><br><span class="line">          prepareShuffleServicesForShuffleMapStage(s)  </span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">          <span class="comment">// Disable Shuffle merge for the retry/reuse of the same shuffle dependency if it has  </span></span><br><span class="line">          <span class="comment">// already been merge finalized. If the shuffle dependency was previously assigned          // merger locations but the corresponding shuffle map stage did not complete          // successfully, we would still enable push for its retry.  </span></span><br><span class="line">          s.shuffleDep.setShuffleMergeAllowed(<span class="literal">false</span>)  </span><br><span class="line">          logInfo(s<span class="string">&quot;Push-based shuffle disabled for $stage ($&#123;stage.name&#125;) since it&quot;</span> +  </span><br><span class="line">            <span class="string">&quot; is already shuffle merge finalized&quot;</span>)  </span><br><span class="line">        &#125;  </span><br><span class="line">      &#125;  </span><br><span class="line">    <span class="keyword">case</span> s: ResultStage =&gt;  </span><br><span class="line">      outputCommitCoordinator.stageStart(  </span><br><span class="line">        stage = s.id, maxPartitionId = s.rdd.partitions.length - <span class="number">1</span>)  </span><br><span class="line">  &#125;  </span><br><span class="line">  val taskIdToLocations: Map[Int, Seq[TaskLocation]] = <span class="keyword">try</span> &#123;  </span><br><span class="line">    stage match &#123;  </span><br><span class="line">      <span class="keyword">case</span> s: ShuffleMapStage =&gt;  </span><br><span class="line">        partitionsToCompute.map &#123; id =&gt; (id, getPreferredLocs(stage.rdd, id))&#125;.toMap  </span><br><span class="line">      <span class="keyword">case</span> s: ResultStage =&gt;  </span><br><span class="line">        partitionsToCompute.map &#123; id =&gt;  </span><br><span class="line">          <span class="type">val</span> <span class="variable">p</span> <span class="operator">=</span> s.partitions(id)  </span><br><span class="line">          (id, getPreferredLocs(stage.rdd, p))  </span><br><span class="line">        &#125;.toMap  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;  </span><br><span class="line">    <span class="keyword">case</span> <span class="title function_">NonFatal</span><span class="params">(e)</span> =&gt;  </span><br><span class="line">      stage.makeNewStageAttempt(partitionsToCompute.size)  </span><br><span class="line">      listenerBus.post(SparkListenerStageSubmitted(stage.latestInfo,  </span><br><span class="line">        Utils.cloneProperties(properties)))  </span><br><span class="line">      abortStage(stage, s<span class="string">&quot;Task creation failed: $e\n$&#123;Utils.exceptionString(e)&#125;&quot;</span>, Some(e))  </span><br><span class="line">      runningStages -= stage  </span><br><span class="line">      <span class="keyword">return</span>  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  stage.makeNewStageAttempt(partitionsToCompute.size, taskIdToLocations.values.toSeq)  </span><br><span class="line">  </span><br><span class="line">  <span class="comment">// If there are tasks to execute, record the submission time of the stage. Otherwise,  </span></span><br><span class="line">  <span class="comment">// post the even without the submission time, which indicates that this stage was  // skipped.  if (partitionsToCompute.nonEmpty) &#123;  </span></span><br><span class="line">    stage.latestInfo.submissionTime = Some(clock.getTimeMillis())  </span><br><span class="line">  &#125;  </span><br><span class="line">  listenerBus.post(SparkListenerStageSubmitted(stage.latestInfo,  </span><br><span class="line">    Utils.cloneProperties(properties)))  </span><br><span class="line">  </span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> Maybe we can keep the taskBinary in Stage to avoid serializing it multiple times.  </span></span><br><span class="line">  <span class="comment">// Broadcasted binary for the task, used to dispatch tasks to executors. Note that we broadcast  </span></span><br><span class="line">  <span class="comment">// the serialized copy of the RDD and for each task we will deserialize it, which means each  // task gets a different copy of the RDD. This provides stronger isolation between tasks that  // might modify state of objects referenced in their closures. This is necessary in Hadoop  // where the JobConf/Configuration object is not thread-safe.  var taskBinary: Broadcast[Array[Byte]] = null  </span></span><br><span class="line">  <span class="keyword">var</span> partitions: Array[Partition] = <span class="literal">null</span>  </span><br><span class="line">  <span class="keyword">try</span> &#123;  </span><br><span class="line">    <span class="comment">// For ShuffleMapTask, serialize and broadcast (rdd, shuffleDep).  </span></span><br><span class="line">    <span class="comment">// For ResultTask, serialize and broadcast (rdd, func).    var taskBinaryBytes: Array[Byte] = null  </span></span><br><span class="line">    <span class="comment">// taskBinaryBytes and partitions are both effected by the checkpoint status. We need  </span></span><br><span class="line">    <span class="comment">// this synchronization in case another concurrent job is checkpointing this RDD, so we get a    // consistent view of both variables.    RDDCheckpointData.synchronized &#123;  </span></span><br><span class="line">      taskBinaryBytes = stage match &#123;  </span><br><span class="line">        <span class="keyword">case</span> stage: ShuffleMapStage =&gt;  </span><br><span class="line">          JavaUtils.bufferToArray(  </span><br><span class="line">            closureSerializer.serialize((stage.rdd, stage.shuffleDep): AnyRef))  </span><br><span class="line">        <span class="keyword">case</span> stage: ResultStage =&gt;  </span><br><span class="line">          JavaUtils.bufferToArray(closureSerializer.serialize((stage.rdd, stage.func): AnyRef))  </span><br><span class="line">      &#125;  </span><br><span class="line">  </span><br><span class="line">      partitions = stage.rdd.partitions  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> (taskBinaryBytes.length &gt; TaskSetManager.TASK_SIZE_TO_WARN_KIB * <span class="number">1024</span>) &#123;  </span><br><span class="line">      logWarning(s<span class="string">&quot;Broadcasting large task binary with size &quot;</span> +  </span><br><span class="line">        s<span class="string">&quot;$&#123;Utils.bytesToString(taskBinaryBytes.length)&#125;&quot;</span>)  </span><br><span class="line">    &#125;  </span><br><span class="line">    taskBinary = sc.broadcast(taskBinaryBytes)  </span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;  </span><br><span class="line">    <span class="comment">// In the case of a failure during serialization, abort the stage.  </span></span><br><span class="line">    <span class="keyword">case</span> e: NotSerializableException =&gt;  </span><br><span class="line">      abortStage(stage, <span class="string">&quot;Task not serializable: &quot;</span> + e.toString, Some(e))  </span><br><span class="line">      runningStages -= stage  </span><br><span class="line">  </span><br><span class="line">      <span class="comment">// Abort execution  </span></span><br><span class="line">      <span class="keyword">return</span>  </span><br><span class="line">    <span class="keyword">case</span> e: Throwable =&gt;  </span><br><span class="line">      abortStage(stage, s<span class="string">&quot;Task serialization failed: $e\n$&#123;Utils.exceptionString(e)&#125;&quot;</span>, Some(e))  </span><br><span class="line">      runningStages -= stage  </span><br><span class="line">  </span><br><span class="line">      <span class="comment">// Abort execution  </span></span><br><span class="line">      <span class="keyword">return</span>  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  val tasks: Seq[Task[_]] = <span class="keyword">try</span> &#123;  </span><br><span class="line">    <span class="type">val</span> <span class="variable">serializedTaskMetrics</span> <span class="operator">=</span> closureSerializer.serialize(stage.latestInfo.taskMetrics).array()  </span><br><span class="line">    stage match &#123;  </span><br><span class="line">      <span class="keyword">case</span> stage: ShuffleMapStage =&gt;  </span><br><span class="line">        stage.pendingPartitions.clear()  </span><br><span class="line">        partitionsToCompute.map &#123; id =&gt;  </span><br><span class="line">          <span class="type">val</span> <span class="variable">locs</span> <span class="operator">=</span> taskIdToLocations(id)  </span><br><span class="line">          <span class="type">val</span> <span class="variable">part</span> <span class="operator">=</span> partitions(id)  </span><br><span class="line">          stage.pendingPartitions += id  </span><br><span class="line">          <span class="keyword">new</span> <span class="title class_">ShuffleMapTask</span>(stage.id, stage.latestInfo.attemptNumber, taskBinary,  </span><br><span class="line">            part, stage.numPartitions, locs, properties, serializedTaskMetrics, Option(jobId),  </span><br><span class="line">            Option(sc.applicationId), sc.applicationAttemptId, stage.rdd.isBarrier())  </span><br><span class="line">        &#125;  </span><br><span class="line">  </span><br><span class="line">      <span class="keyword">case</span> stage: ResultStage =&gt;  </span><br><span class="line">        partitionsToCompute.map &#123; id =&gt;  </span><br><span class="line">          val p: Int = stage.partitions(id)  </span><br><span class="line">          <span class="type">val</span> <span class="variable">part</span> <span class="operator">=</span> partitions(p)  </span><br><span class="line">          <span class="type">val</span> <span class="variable">locs</span> <span class="operator">=</span> taskIdToLocations(id)  </span><br><span class="line">          <span class="keyword">new</span> <span class="title class_">ResultTask</span>(stage.id, stage.latestInfo.attemptNumber,  </span><br><span class="line">            taskBinary, part, stage.numPartitions, locs, id, properties, serializedTaskMetrics,  </span><br><span class="line">            Option(jobId), Option(sc.applicationId), sc.applicationAttemptId,  </span><br><span class="line">            stage.rdd.isBarrier())  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;  </span><br><span class="line">    <span class="keyword">case</span> <span class="title function_">NonFatal</span><span class="params">(e)</span> =&gt;  </span><br><span class="line">      abortStage(stage, s<span class="string">&quot;Task creation failed: $e\n$&#123;Utils.exceptionString(e)&#125;&quot;</span>, Some(e))  </span><br><span class="line">      runningStages -= stage  </span><br><span class="line">      <span class="keyword">return</span>  </span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> (tasks.nonEmpty) &#123;  </span><br><span class="line">    logInfo(s<span class="string">&quot;Submitting $&#123;tasks.size&#125; missing tasks from $stage ($&#123;stage.rdd&#125;) (first 15 &quot;</span> +  </span><br><span class="line">      s<span class="string">&quot;tasks are for partitions $&#123;tasks.take(15).map(_.partitionId)&#125;)&quot;</span>)  </span><br><span class="line">    <span class="type">val</span> <span class="variable">shuffleId</span> <span class="operator">=</span> stage match &#123;  </span><br><span class="line">      <span class="keyword">case</span> s: ShuffleMapStage =&gt; Some(s.shuffleDep.shuffleId)  </span><br><span class="line">      <span class="keyword">case</span> _: ResultStage =&gt; None  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    taskScheduler.submitTasks(<span class="keyword">new</span> <span class="title class_">TaskSet</span>(  </span><br><span class="line">      tasks.toArray, stage.id, stage.latestInfo.attemptNumber, jobId, properties,  </span><br><span class="line">      stage.resourceProfileId, shuffleId))  </span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">    <span class="comment">// Because we posted SparkListenerStageSubmitted earlier, we should mark  </span></span><br><span class="line">    <span class="comment">// the stage as completed here in case there are no tasks to run    markStageAsFinished(stage, None)  </span></span><br><span class="line">  </span><br><span class="line">    stage match &#123;  </span><br><span class="line">      <span class="keyword">case</span> stage: ShuffleMapStage =&gt;  </span><br><span class="line">        logDebug(s<span class="string">&quot;Stage $&#123;stage&#125; is actually done; &quot;</span> +  </span><br><span class="line">            s<span class="string">&quot;(available: $&#123;stage.isAvailable&#125;,&quot;</span> +  </span><br><span class="line">            s<span class="string">&quot;available outputs: $&#123;stage.numAvailableOutputs&#125;,&quot;</span> +  </span><br><span class="line">            s<span class="string">&quot;partitions: $&#123;stage.numPartitions&#125;)&quot;</span>)  </span><br><span class="line">        markMapStageJobsAsFinished(stage)  </span><br><span class="line">      <span class="keyword">case</span> stage : ResultStage =&gt;  </span><br><span class="line">        logDebug(s<span class="string">&quot;Stage $&#123;stage&#125; is actually done; (partitions: $&#123;stage.numPartitions&#125;)&quot;</span>)  </span><br><span class="line">    &#125;  </span><br><span class="line">    submitWaitingChildStages(stage)  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码上面的部分是如何去创建<code>Task</code>, 当<code>tasks</code>不为空是会调用<code>taskScheduler.submitTask</code>来提交Task. <code>Task</code>的信息是通过<code>sparkContext.broadcast</code>来广播到每个executor上的.<br>注意当有上游依赖时,<code>finialStage</code>还在<code>waitingStages</code>中.</p>
<h2 id="TaskScheduler"><a href="#TaskScheduler" class="headerlink" title="TaskScheduler"></a>TaskScheduler</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">override def <span class="title function_">submitTasks</span><span class="params">(taskSet: TaskSet)</span>: Unit = &#123;  </span><br><span class="line">  <span class="type">val</span> <span class="variable">tasks</span> <span class="operator">=</span> taskSet.tasks  </span><br><span class="line">  <span class="title function_">logInfo</span><span class="params">(<span class="string">&quot;Adding task set &quot;</span> + taskSet.id + <span class="string">&quot; with &quot;</span> + tasks.length + <span class="string">&quot; tasks &quot;</span>  </span></span><br><span class="line"><span class="params">    + <span class="string">&quot;resource profile &quot;</span> + taskSet.resourceProfileId)</span>  </span><br><span class="line">  <span class="built_in">this</span>.<span class="keyword">synchronized</span> &#123;  </span><br><span class="line">    <span class="type">val</span> <span class="variable">manager</span> <span class="operator">=</span> createTaskSetManager(taskSet, maxTaskFailures)  </span><br><span class="line">    <span class="type">val</span> <span class="variable">stage</span> <span class="operator">=</span> taskSet.stageId  </span><br><span class="line">    <span class="type">val</span> <span class="variable">stageTaskSets</span> <span class="operator">=</span>  </span><br><span class="line">      taskSetsByStageIdAndAttempt.getOrElseUpdate(stage, <span class="keyword">new</span> <span class="title class_">HashMap</span>[Int, TaskSetManager])  </span><br><span class="line">   </span><br><span class="line">    stageTaskSets.foreach &#123; <span class="keyword">case</span> (_, ts) =&gt;  </span><br><span class="line">      ts.isZombie = <span class="literal">true</span>  </span><br><span class="line">    &#125;  </span><br><span class="line">    stageTaskSets(taskSet.stageAttemptId) = manager  </span><br><span class="line">    schedulableBuilder.addTaskSetManager(manager, manager.taskSet.properties)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> (!isLocal &amp;&amp; !hasReceivedTask) &#123;  </span><br><span class="line">      starvationTimer.scheduleAtFixedRate(<span class="keyword">new</span> <span class="title class_">TimerTask</span>() &#123;  </span><br><span class="line">        override def <span class="title function_">run</span><span class="params">()</span>: Unit = &#123;  </span><br><span class="line">          <span class="keyword">if</span> (!hasLaunchedTask) &#123;  </span><br><span class="line">            logWarning(<span class="string">&quot;Initial job has not accepted any resources; &quot;</span> +  </span><br><span class="line">              <span class="string">&quot;check your cluster UI to ensure that workers are registered &quot;</span> +  </span><br><span class="line">              <span class="string">&quot;and have sufficient resources&quot;</span>)  </span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">            <span class="built_in">this</span>.cancel()  </span><br><span class="line">          &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">      &#125;, STARVATION_TIMEOUT_MS, STARVATION_TIMEOUT_MS)  </span><br><span class="line">    &#125;  </span><br><span class="line">    hasReceivedTask = <span class="literal">true</span>  </span><br><span class="line">  &#125;  </span><br><span class="line">  backend.reviveOffers()  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>创建完<code>TaskSetManager</code>后, 调用了<code>SchedulerBackend.reviverOffers</code>.<br><code>SchedulerBackend</code>的实现类为<code>CoarseGrainedSchedulerBackend</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">override def <span class="title function_">reviveOffers</span><span class="params">()</span>: Unit = Utils.tryLogNonFatalError &#123;  </span><br><span class="line">  driverEndpoint.send(ReviveOffers)  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">override def receive: PartialFunction[Any, Unit] = &#123;</span><br><span class="line">	...</span><br><span class="line">	<span class="type">case</span> <span class="variable">ReviveOffers</span> <span class="operator">=</span>&gt;  </span><br><span class="line">	  makeOffers()</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> def <span class="title function_">makeOffers</span><span class="params">()</span>: Unit = &#123;  </span><br><span class="line">  <span class="comment">// Make sure no executor is killed while some task is launching on it  </span></span><br><span class="line">  <span class="type">val</span> <span class="variable">taskDescs</span> <span class="operator">=</span> withLock &#123;  </span><br><span class="line">    <span class="comment">// Filter out executors under killing  </span></span><br><span class="line">    <span class="type">val</span> <span class="variable">activeExecutors</span> <span class="operator">=</span> executorDataMap.filterKeys(isExecutorActive)  </span><br><span class="line">    <span class="type">val</span> <span class="variable">workOffers</span> <span class="operator">=</span> activeExecutors.map &#123;  </span><br><span class="line">      <span class="keyword">case</span> (id, executorData) =&gt; buildWorkerOffer(id, executorData)  </span><br><span class="line">    &#125;.toIndexedSeq  </span><br><span class="line">    scheduler.resourceOffers(workOffers, <span class="literal">true</span>)  </span><br><span class="line">  &#125;  </span><br><span class="line">  <span class="keyword">if</span> (taskDescs.nonEmpty) &#123;  </span><br><span class="line">    launchTasks(taskDescs)  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> def <span class="title function_">launchTasks</span><span class="params">(tasks: Seq[Seq[TaskDescription]])</span>: Unit = &#123;  </span><br><span class="line">  <span class="keyword">for</span> (task &lt;- tasks.flatten) &#123;  </span><br><span class="line">    <span class="type">val</span> <span class="variable">serializedTask</span> <span class="operator">=</span> TaskDescription.encode(task)  </span><br><span class="line">    <span class="keyword">if</span> (serializedTask.limit() &gt;= maxRpcMessageSize) &#123;  </span><br><span class="line">      Option(scheduler.taskIdToTaskSetManager.get(task.taskId)).foreach &#123; taskSetMgr =&gt;  </span><br><span class="line">        <span class="keyword">try</span> &#123;  </span><br><span class="line">          <span class="type">var</span> <span class="variable">msg</span> <span class="operator">=</span> <span class="string">&quot;Serialized task %s:%d was %d bytes, which exceeds max allowed: &quot;</span> +  </span><br><span class="line">            s<span class="string">&quot;$&#123;RPC_MESSAGE_MAX_SIZE.key&#125; (%d bytes). Consider increasing &quot;</span> +  </span><br><span class="line">            s<span class="string">&quot;$&#123;RPC_MESSAGE_MAX_SIZE.key&#125; or using broadcast variables for large values.&quot;</span>          msg = msg.format(task.taskId, task.index, serializedTask.limit(), maxRpcMessageSize)  </span><br><span class="line">          taskSetMgr.abort(msg)  </span><br><span class="line">        &#125; <span class="keyword">catch</span> &#123;  </span><br><span class="line">          <span class="keyword">case</span> e: Exception =&gt; logError(<span class="string">&quot;Exception in error callback&quot;</span>, e)  </span><br><span class="line">        &#125;  </span><br><span class="line">      &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">else</span> &#123;  </span><br><span class="line">      <span class="type">val</span> <span class="variable">executorData</span> <span class="operator">=</span> executorDataMap(task.executorId)  </span><br><span class="line">      <span class="comment">// Do resources allocation here. The allocated resources will get released after the task  </span></span><br><span class="line">      <span class="comment">// finishes.      executorData.freeCores -= task.cpus  </span></span><br><span class="line">      task.resources.foreach &#123; <span class="keyword">case</span> (rName, rInfo) =&gt;  </span><br><span class="line">        <span class="keyword">assert</span>(executorData.resourcesInfo.contains(rName))  </span><br><span class="line">        executorData.resourcesInfo(rName).acquire(rInfo.addresses)  </span><br><span class="line">      &#125;  </span><br><span class="line">  </span><br><span class="line">      logDebug(s<span class="string">&quot;Launching task $&#123;task.taskId&#125; on executor id: $&#123;task.executorId&#125; hostname: &quot;</span> +  </span><br><span class="line">        s<span class="string">&quot;$&#123;executorData.executorHost&#125;.&quot;</span>)  </span><br><span class="line">  </span><br><span class="line">      executorData.executorEndpoint.send(LaunchTask(<span class="keyword">new</span> <span class="title class_">SerializableBuffer</span>(serializedTask)))  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这里将task编码后, 发送到每个executor上. </p>
<h1 id="Executor"><a href="#Executor" class="headerlink" title="Executor"></a>Executor</h1><p>在executor上, 当接受到<code>LauncherTask</code>类型的消息时</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">override def receive: PartialFunction[Any, Unit] = &#123;  </span><br><span class="line">  ..  </span><br><span class="line">  <span class="keyword">case</span> <span class="title function_">LaunchTask</span><span class="params">(data)</span> =&gt;  </span><br><span class="line">    <span class="keyword">if</span> (executor == <span class="literal">null</span>) &#123;  </span><br><span class="line">      exitExecutor(<span class="number">1</span>, <span class="string">&quot;Received LaunchTask command but executor was null&quot;</span>)  </span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">      <span class="type">val</span> <span class="variable">taskDesc</span> <span class="operator">=</span> TaskDescription.decode(data.value)  </span><br><span class="line">      logInfo(<span class="string">&quot;Got assigned task &quot;</span> + taskDesc.taskId)  </span><br><span class="line">      taskResources(taskDesc.taskId) = taskDesc.resources  </span><br><span class="line">      executor.launchTask(<span class="built_in">this</span>, taskDesc)  </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>反序列化化Task信息, 然后交到线程池中执行.<br>当任务完成后, <code>TaskSetManager</code>中的方法会将信息发送给<code>DagScheduler</code>.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def <span class="title function_">handleSuccessfulTask</span><span class="params">(tid: Long, result: DirectTaskResult[_])</span>: Unit = &#123;</span><br><span class="line">	sched.dagScheduler.taskEnded(tasks(index), Success, result.value(), result.accumUpdates,  </span><br><span class="line">  result.metricPeaks, info)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> 在<code>DAGScheduler</code>中, </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">def <span class="title function_">taskEnded</span><span class="params">(  </span></span><br><span class="line"><span class="params">    task: Task[_],  </span></span><br><span class="line"><span class="params">    reason: TaskEndReason,  </span></span><br><span class="line"><span class="params">    result: Any,  </span></span><br><span class="line"><span class="params">    accumUpdates: Seq[AccumulatorV2[_, _]],  </span></span><br><span class="line"><span class="params">    metricPeaks: Array[Long],  </span></span><br><span class="line"><span class="params">    taskInfo: TaskInfo)</span>: Unit = &#123;  </span><br><span class="line">  eventProcessLoop.post(  </span><br><span class="line">    CompletionEvent(task, reason, result, accumUpdates, metricPeaks, taskInfo))  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[scheduler] def <span class="title function_">handleTaskCompletion</span><span class="params">(event: CompletionEvent)</span>: Unit = &#123;</span><br><span class="line">event.reason match &#123;  </span><br><span class="line">  <span class="type">case</span> <span class="variable">Success</span> <span class="operator">=</span>&gt;  </span><br><span class="line">	...</span><br><span class="line">    task match &#123;  </span><br><span class="line">	  ...</span><br><span class="line">      <span class="keyword">case</span> smt: ShuffleMapTask =&gt;  </span><br><span class="line">        <span class="type">val</span> <span class="variable">shuffleStage</span> <span class="operator">=</span> stage.asInstanceOf[ShuffleMapStage]  </span><br><span class="line">        shuffleStage.pendingPartitions -= task.partitionId  </span><br><span class="line">        <span class="type">val</span> <span class="variable">status</span> <span class="operator">=</span> event.result.asInstanceOf[MapStatus]  </span><br><span class="line">        <span class="type">val</span> <span class="variable">execId</span> <span class="operator">=</span> status.location.executorId  </span><br><span class="line">        <span class="title function_">logDebug</span><span class="params">(<span class="string">&quot;ShuffleMapTask finished on &quot;</span> + execId)</span>  </span><br><span class="line">        <span class="keyword">if</span> (executorFailureEpoch.contains(execId) &amp;&amp;  </span><br><span class="line">            smt.epoch &lt;= executorFailureEpoch(execId)) &#123;  </span><br><span class="line">          logInfo(s<span class="string">&quot;Ignoring possibly bogus $smt completion from executor $execId&quot;</span>)  </span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">          <span class="comment">// The epoch of the task is acceptable (i.e., the task was launched after the most  </span></span><br><span class="line">          <span class="comment">// recent failure we&#x27;re aware of for the executor), so mark the task&#x27;s output as          // available.          mapOutputTracker.registerMapOutput(  </span></span><br><span class="line">            shuffleStage.shuffleDep.shuffleId, smt.partitionId, status)  </span><br><span class="line">        &#125;  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> (runningStages.contains(shuffleStage) &amp;&amp; shuffleStage.pendingPartitions.isEmpty) &#123;  </span><br><span class="line">          <span class="keyword">if</span> (!shuffleStage.shuffleDep.isShuffleMergeFinalizedMarked &amp;&amp;  </span><br><span class="line">            shuffleStage.shuffleDep.getMergerLocs.nonEmpty) &#123;  </span><br><span class="line">            checkAndScheduleShuffleMergeFinalize(shuffleStage)  </span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">            processShuffleMapStageCompletion(shuffleStage)  </span><br><span class="line">          &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里有一句<code>processShuffleMapStageCompletion(shuffleStage)</code>, 当有上游依赖时<code>ResultStage</code>会被放到<code>waitingStages</code>, 还未被执行. </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> def <span class="title function_">processShuffleMapStageCompletion</span><span class="params">(shuffleStage: ShuffleMapStage)</span>: Unit = &#123;  </span><br><span class="line">  markStageAsFinished(shuffleStage)  </span><br><span class="line">  logInfo(<span class="string">&quot;looking for newly runnable stages&quot;</span>)  </span><br><span class="line">  logInfo(<span class="string">&quot;running: &quot;</span> + runningStages)  </span><br><span class="line">  logInfo(<span class="string">&quot;waiting: &quot;</span> + waitingStages)  </span><br><span class="line">  logInfo(<span class="string">&quot;failed: &quot;</span> + failedStages)  </span><br><span class="line">  </span><br><span class="line">  mapOutputTracker.incrementEpoch()  </span><br><span class="line">  </span><br><span class="line">  clearCacheLocs()  </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> (!shuffleStage.isAvailable) &#123;  </span><br><span class="line">    <span class="comment">// Some tasks had failed; let&#x27;s resubmit this shuffleStage.  </span></span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> Lower-level scheduler should also deal with this  </span></span><br><span class="line">    logInfo(<span class="string">&quot;Resubmitting &quot;</span> + shuffleStage + <span class="string">&quot; (&quot;</span> + shuffleStage.name +  </span><br><span class="line">      <span class="string">&quot;) because some of its tasks had failed: &quot;</span> +  </span><br><span class="line">      shuffleStage.findMissingPartitions().mkString(<span class="string">&quot;, &quot;</span>))  </span><br><span class="line">    submitStage(shuffleStage)  </span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;  </span><br><span class="line">    markMapStageJobsAsFinished(shuffleStage)  </span><br><span class="line">    submitWaitingChildStages(shuffleStage)  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> def <span class="title function_">submitWaitingChildStages</span><span class="params">(parent: Stage)</span>: Unit = &#123;  </span><br><span class="line">  logTrace(s<span class="string">&quot;Checking if any dependencies of $parent are now runnable&quot;</span>)  </span><br><span class="line">  logTrace(<span class="string">&quot;running: &quot;</span> + runningStages)  </span><br><span class="line">  logTrace(<span class="string">&quot;waiting: &quot;</span> + waitingStages)  </span><br><span class="line">  logTrace(<span class="string">&quot;failed: &quot;</span> + failedStages)  </span><br><span class="line">  <span class="type">val</span> <span class="variable">childStages</span> <span class="operator">=</span> waitingStages.filter(_.parents.contains(parent)).toArray  </span><br><span class="line">  waitingStages --= childStages  </span><br><span class="line">  <span class="title function_">for</span> <span class="params">(stage &lt;- childStages.sortBy(_.firstJobId)</span>) &#123;  </span><br><span class="line">    submitStage(stage)  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里会将Stage从<code>waitingStages</code>中拿出来, 然后重新提交. </p>

<br>
<h2>Tags: </h2>
  <p><a class="classtest-link" href="/tags/spark/" rel="tag">spark</a> — 2023年7月30日</p>
  

  <script async src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
  });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

  <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
<script>
  $(document).ready(() => {
    const maraidConfig = {
      theme: "default",
      logLevel: 3,
      flowchart: { curve: "linear" },
      gantt: { axisFormat: "%m/%d/%Y" },
      sequence: { actorMargin: 50 },
    };
    mermaid.initialize(maraidConfig);
  });
</script>

        </div>
        <!-- <div class="row mt-2">
  <h3>Search</h3>
  <div><input id="search-text" title="search" class="search-text" type="text" placeholder="search......"></div>
  <div style="margin-top: 1.5rem;">
    <ul id="result"></ul>
  </div>
</div> -->
        <div class="row mt-2">
  
    <div class="eight columns">
      <p id="madewith">Made with ❤ and
        <a class="footer-link icon" href="https://hexo.io" target="_blank" style="text-decoration: none;" rel="noreferrer" aria-label="Hexo.io">
        <svg class="hexo svg-hov" width="14" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><title>Hexo.js</title><path d="M12 .007L1.57 6.056V18.05L12 23.995l10.43-6.049V5.952L12 .007zm4.798 17.105l-.939.521-.939-.521V12.94H9.08v4.172l-.94.521-.938-.521V6.89l.939-.521.939.521v4.172h5.84V6.89l.94-.521.938.521v10.222z"/></svg>
        </a>
        
    </div>

    <!-- Sepcial thanks to https://simpleicons.org/ for the icons -->
    <div class="four columns mb-3 posisi" >
      
      <a class="ml-0 footer-link icon" href="https://github.com/liunaijie" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="GitHub">
        <svg class="github svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      </a>
      

      

      

      

      
      
        <a class="ml-0 footer-link icon" href="mailto:jarvis@apache.org" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="Email">
          <svg class="email svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Email</title><path d="M12 12.713l11.985-7.99c-.01-.01-11.985-7.723-11.985-7.723s-11.975 7.713-11.985 7.723l11.985 7.99zm0 2.287l-12-8v14h24v-14l-12 8z"/></svg>
        </a>
        
    </div>
  
</div>

      </div>

    </div>

  </div>
  <script src="/js/nanobar.min.js"></script>

  <script>
    var options = {
      classname: 'nanobar',
      id: 'myNanobar'
    };
    var nanobar = new Nanobar(options);
    nanobar.go(30);
    nanobar.go(76);
    nanobar.go(100);
  </script>

</body>

</html>