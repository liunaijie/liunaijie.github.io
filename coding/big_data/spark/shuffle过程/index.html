<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta property="og:url" content="https://www.liunaijie.top/coding/big_data/spark/shuffle%E8%BF%87%E7%A8%8B/">
  <meta property="og:site_name" content="Jarvis`s library">
  <meta property="og:title" content="Spark-Shuffle过程">
  <meta property="og:description" content="Map阶段的输出是什么 Map阶段最终生成的数据会以中间文件的形式物化到磁盘中, 这些文件存储在spark.local.dir设置的文件目录中. 中间文件包含两种类型:
后缀为data的数据文件
存储的内容是Map阶段生成的待分发数据
后缀为index的索引文件
记录的是数据文件中不同分区(Reduce阶段的分区)的偏移地址. 分区数量与Reduce阶段的并行度保持一致.
Map阶段的每个Task都会生成这样的一组文件, 因此中间文件的数量与Map阶段的并行度保持一致.
数据生成过程 计算目标分区 在Spark中, 每条数据的分区是由Key的哈希值决定的
写入缓存区或溢写到文件 GroupByKey的实现 计算完目标分区后, Map Task会把每条记录和它的目标分区, 放到一个特殊的数据结构PartitionedPairBuffer里, 这个数据结构本质上是一个数组形式的缓存结构.
每条数据都会占用数组中相邻的两个元素空间, 第一个元素存储(目标分区, Key), 第二个元素存储值.
这个数组的长度不可能无限大来存储所有Map端的元素. 所以Spark有一种机制, 来保障在数据总量超过可用内存的情况下, 依然能够完成计算. 这种机制就是: 排序、溢出、归并.
举个例子:
假如我们的PartitionedPairBuffer 的数组长度为8, 也就是说可以存储4个元素. 而我们的Map端共有16个元素, 那么就会需要4批才能完成计算. 在处理第二批的数据时, Spark会将第一批的数据溢写到磁盘的临时文件上.
在溢写时, 会对PartitionedPairBuffer 中已有的数据, 按照目标分区以及Key进行排序后再进行写入, 所以临时文件中的数据是有序的.
在处理第四批的时, 这时已经是最后一批, 所以这次不再需要溢写到临时文件. 现在的数据分布在3个临时文件中, 还有缓存在PartitionedPairBuffer中.
最后, 会从这两个输入源中(临时文件, 缓存区)生成最终的数据文件和索引文件. 并且由于每个文件都是有序的, 所以在合并时使用了归并算法.
主要步骤为:
对于分片中的数据记录, 逐一计算其目标分区, 并将其填充到PartitionedPairBuffer PartitionedPairBuffer 填满后, 如果后续还有未处理的数据, 则对Buffer中的数据按(Partition ID, Key)进行排序, 将Buffer中的文件溢出到临时文件, 同时清空缓存区 重复步骤1, 2. 直到分片内的所有数据都被处理 对所有临时文件和PartitionedPairBuffer归并排序, 最终生成数据文件和索引文件 ReduceByKey ReduceByKey的计算步骤与GroupByKey的一样, 都是先填充内存数据结构, 然后排序溢出, 最后归并排序.">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="coding">
    <meta property="article:published_time" content="2022-04-01T00:00:00+00:00">
    <meta property="article:modified_time" content="2022-04-01T00:00:00+00:00">
    <meta property="article:tag" content="Spark">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Spark-Shuffle过程">
  <meta name="twitter:description" content="Map阶段的输出是什么 Map阶段最终生成的数据会以中间文件的形式物化到磁盘中, 这些文件存储在spark.local.dir设置的文件目录中. 中间文件包含两种类型:
后缀为data的数据文件
存储的内容是Map阶段生成的待分发数据
后缀为index的索引文件
记录的是数据文件中不同分区(Reduce阶段的分区)的偏移地址. 分区数量与Reduce阶段的并行度保持一致.
Map阶段的每个Task都会生成这样的一组文件, 因此中间文件的数量与Map阶段的并行度保持一致.
数据生成过程 计算目标分区 在Spark中, 每条数据的分区是由Key的哈希值决定的
写入缓存区或溢写到文件 GroupByKey的实现 计算完目标分区后, Map Task会把每条记录和它的目标分区, 放到一个特殊的数据结构PartitionedPairBuffer里, 这个数据结构本质上是一个数组形式的缓存结构.
每条数据都会占用数组中相邻的两个元素空间, 第一个元素存储(目标分区, Key), 第二个元素存储值.
这个数组的长度不可能无限大来存储所有Map端的元素. 所以Spark有一种机制, 来保障在数据总量超过可用内存的情况下, 依然能够完成计算. 这种机制就是: 排序、溢出、归并.
举个例子:
假如我们的PartitionedPairBuffer 的数组长度为8, 也就是说可以存储4个元素. 而我们的Map端共有16个元素, 那么就会需要4批才能完成计算. 在处理第二批的数据时, Spark会将第一批的数据溢写到磁盘的临时文件上.
在溢写时, 会对PartitionedPairBuffer 中已有的数据, 按照目标分区以及Key进行排序后再进行写入, 所以临时文件中的数据是有序的.
在处理第四批的时, 这时已经是最后一批, 所以这次不再需要溢写到临时文件. 现在的数据分布在3个临时文件中, 还有缓存在PartitionedPairBuffer中.
最后, 会从这两个输入源中(临时文件, 缓存区)生成最终的数据文件和索引文件. 并且由于每个文件都是有序的, 所以在合并时使用了归并算法.
主要步骤为:
对于分片中的数据记录, 逐一计算其目标分区, 并将其填充到PartitionedPairBuffer PartitionedPairBuffer 填满后, 如果后续还有未处理的数据, 则对Buffer中的数据按(Partition ID, Key)进行排序, 将Buffer中的文件溢出到临时文件, 同时清空缓存区 重复步骤1, 2. 直到分片内的所有数据都被处理 对所有临时文件和PartitionedPairBuffer归并排序, 最终生成数据文件和索引文件 ReduceByKey ReduceByKey的计算步骤与GroupByKey的一样, 都是先填充内存数据结构, 然后排序溢出, 最后归并排序.">

  
  
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#181818">
  <title>
    
    Jarvis`s library - Spark-Shuffle过程
    
  </title>
  
  
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
  
  
  
  <link rel="stylesheet" href="/minima.54cfcb44e10b4015b41a13771763013b79bdba6a92e49ea4a77bb44db465e761.css" integrity="sha256-VM/LROELQBW0GhN3F2MBO3m9umqS5J6kp3u0TbRl52E=">
  
  
  
  <script defer type="text/javascript" src="/minima.b4da24217e147f536fc7dc225886a1ea20bedabe7aed49e546a5d97cc34e4555.js" integrity="sha256-tNokIX4Uf1Nvx9wiWIah6iC&#43;2r567UnlRqXZfMNORVU="></script>
  
  
  
</head>
<script>
  const theme_config = 'system'
  const theme_light = theme_config === 'system' ? 'light' : theme_config;
  let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : theme_light;
  console.debug(theme);

  try {
    localStorage.setItem('theme', theme);
    window.minima_theme = theme;
    document.querySelector('html').classList.add(theme);
  } catch (e) {
    console.error(e);
  }
</script>



<body>
  <header class="mt-3 mb-8">
  <div class="container mx-auto">
    <nav class="flex justify-between items-center">
      <div class="flex items-center">
        
        <div id="theme-switch" class="text-2xl cursor-pointer"></div>
      </div>
      <ul class="flex items-center text-base font-semibold
        whitespace-nowrap overflow-x-auto overflow-y-hidden">
        
        <li class="ml-2 mr-2">
          
          <a href='/'>首页</a>
          
        </li>
        
        <li class="ml-2 mr-2">
          
          <a href="/tags">标签</a>
          
        </li>
        
        <li class="ml-2 mr-2">
          
          <a href="/search">搜索</a>
          
        </li>
        
        <li class="ml-2 mr-2">
          
          <a href="/about">关于</a>
          
        </li>
        
      </ul>
      <ul class="flex item-center text-sm font-semibold">
        
        <li class="ml-2"><a href="https://www.liunaijie.top/"></a></li>
        
      </ul>
    </nav>
  </div>
</header>

  
<div class="container mx-auto">
  <h1 class="text-4xl font-extrabold mt-6 mb-6">Spark-Shuffle过程</h1>
  <div class="mb-3 text-sm flex justify-between ">
    <div>
      
      发布于 &mdash; 2022 年 04 月 01 日
      
      
    </div>
    
    <div>
      
      
      <a class="ml-1" href="/tags/Spark">#Spark</a>
      
    </div>
    
  </div>
  <main class="mb-8">
    <p></p>
    <article class="md">
      <h1 id="map阶段的输出是什么">Map阶段的输出是什么</h1>
<p>Map阶段最终生成的数据会以中间文件的形式物化到磁盘中, 这些文件存储在<code>spark.local.dir</code>设置的文件目录中. 中间文件包含两种类型:</p>
<ul>
<li>
<p>后缀为data的数据文件</p>
<p>存储的内容是Map阶段生成的待分发数据</p>
</li>
<li>
<p>后缀为index的索引文件</p>
<p>记录的是数据文件中不同分区(Reduce阶段的分区)的偏移地址. 分区数量与Reduce阶段的并行度保持一致.</p>
</li>
</ul>
<p>Map阶段的每个Task都会生成这样的一组文件, 因此中间文件的数量与Map阶段的并行度保持一致.</p>
<h1 id="数据生成过程">数据生成过程</h1>
<h2 id="计算目标分区">计算目标分区</h2>
<p>在Spark中, 每条数据的分区是由Key的哈希值决定的</p>
<h2 id="写入缓存区或溢写到文件">写入缓存区或溢写到文件</h2>
<h3 id="groupbykey的实现">GroupByKey的实现</h3>
<p>计算完目标分区后, Map Task会把每条记录和它的目标分区, 放到一个特殊的数据结构<code>PartitionedPairBuffer</code>里, 这个数据结构本质上是一个数组形式的缓存结构.</p>
<p>每条数据都会占用数组中相邻的两个元素空间, 第一个元素存储(目标分区, Key), 第二个元素存储值.</p>
<p><img src="https://raw.githubusercontent.com/liunaijie/images/master/202308121617362.png" alt=""></p>
<p>这个数组的长度不可能无限大来存储所有Map端的元素. 所以Spark有一种机制, 来保障在数据总量超过可用内存的情况下, 依然能够完成计算. 这种机制就是: <strong>排序、溢出、归并.</strong></p>
<p>举个例子:</p>
<p>假如我们的<code>PartitionedPairBuffer</code> 的数组长度为8, 也就是说可以存储4个元素. 而我们的Map端共有16个元素, 那么就会需要4批才能完成计算. 在处理第二批的数据时, Spark会将第一批的数据溢写到磁盘的临时文件上.</p>
<p>在溢写时, 会对<code>PartitionedPairBuffer</code> 中已有的数据, 按照目标分区以及Key进行排序后再进行写入, 所以<code>临时文件中的数据是有序的</code>.</p>
<p>在处理第四批的时, 这时已经是最后一批, 所以这次不再需要溢写到临时文件. 现在的数据分布在3个临时文件中, 还有缓存在PartitionedPairBuffer中.</p>
<p>最后, 会从这两个输入源中(临时文件, 缓存区)生成最终的数据文件和索引文件. 并且由于每个文件都是有序的, 所以在合并时使用了归并算法.</p>
<p><img src="https://raw.githubusercontent.com/liunaijie/images/master/202308121617650.png" alt=""></p>
<p>主要步骤为:</p>
<ol>
<li>对于分片中的数据记录, 逐一计算其目标分区, 并将其填充到PartitionedPairBuffer</li>
<li><code>PartitionedPairBuffer</code> 填满后, 如果后续还有未处理的数据, 则对Buffer中的数据按(Partition ID, Key)进行排序, 将Buffer中的文件溢出到临时文件, 同时清空缓存区</li>
<li>重复步骤1, 2. 直到分片内的所有数据都被处理</li>
<li>对所有临时文件和<code>PartitionedPairBuffer</code>归并排序, 最终生成数据文件和索引文件</li>
</ol>
<h3 id="reducebykey">ReduceByKey</h3>
<p>ReduceByKey的计算步骤与GroupByKey的一样, 都是先填充内存数据结构, 然后排序溢出, 最后归并排序.</p>
<p>不一样的地方是, <strong>ReduceByKey采用了一种<code>PartitionedAppendOnlyMap</code> 的数据结构来填充数据记录, 这个数据结构是一种Map, 而Map的值是可以累加, 可以更新的.</strong> 所以非常适合用于聚合类的计算场景, 如计数、求和、均值计算、极值计算等.</p>
<p><img src="https://raw.githubusercontent.com/liunaijie/images/master/202308121617612.png" alt=""></p>
<p>相比PartitionedPairBuffer, PartitionedAppendOnlyMap的存储效率要高很多, 溢出数据到磁盘文件的频率也要低很多. 因此最终合并的数据文件也会小很多.</p>
<p><strong>依靠高效的内存存储结构、更少的磁盘文件、更小的文件尺寸. 大幅降低来Shuffle过程中的磁盘和网络开销.</strong></p>
<h1 id="reduce阶段流程">Reduce阶段流程</h1>
<p><img src="https://raw.githubusercontent.com/liunaijie/images/master/202308121617931.png" alt="">
Reduce阶段需要主动从Map端中间文件中拉取数据.</p>
<p>每个Map Task都会生成上图这样的文件, 文件中的分区数与Reduce阶段的并行度一致. 也就是说每个Map Task生成的数据文件, 都包含所有Reduce Task所需的部分数据.</p>
<p>因此, 任何一个Reduce Task都需要从所有的Map Task拉取属于自己的那部分数据. 索引文件用于帮助判定哪部分数据属于哪个Reduce Task.</p>
<p><strong>Reduce Task通过网络拉取中间文件的过程, 实际上就是不同Stages之间数据分发的过程.</strong></p>
<p><img src="https://raw.githubusercontent.com/liunaijie/images/master/202308121618286.png" alt="">
Reduce Task将拉取到的数据块填充到读缓存区, 然后按照任务的计算逻辑不停的消费、处理缓存区中的数据记录.</p>
<h1 id="总结">总结</h1>
<p>对于Shuffle, 它需要消耗所有的硬件资源</p>
<ul>
<li>无论是PartitionedPairBuffer、PartitionedAppendOnlyMap这些内存数据结构, 还是读写缓冲区, 都需要消耗内存资源</li>
<li>由于内存空间有限, 因此溢写的临时文件会引入大量的磁盘I/O, 而且Map阶段输出的中间文件也会消耗磁盘</li>
<li>Reduce阶段的数据拉取, 需要消耗网络I/O.</li>
</ul>
<p>其次, 消耗的不同硬件资源之间很难达到平衡.</p>

    </article>
  </main>
  

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css"
    integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js"
    integrity="sha384-YNHdsYkH6gMx9y3mRkmcJ2mFUjTd0qNQQvY9VYZgQd7DcN7env35GzlmFaZ23JGp"
    crossorigin="anonymous"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js"
    integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl"
    crossorigin="anonymous"></script>

<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            
            
            delimiters: [
                { left: '$$', right: '$$', display: true },
                { left: '$', right: '$', display: false },
                { left: '\\(', right: '\\)', display: false },
                { left: '\\[', right: '\\]', display: true }
            ],
            
            throwOnError: false
        });
    });
</script>





<script 
  src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"
  crossorigin="anonymous">
</script>
<script>
  mermaid.init(undefined, 'code.language-mermaid')
</script>




</div>


  <footer class="mt-8 mb-8">
  <div class="container mx-auto">
    <div class="mt-8 flex flex-col-reverse sm:flex-row sm:justify-between items-center">
      <div class="text-center sm:text-left">
        <p class="mt-0 text-sm"></p>
        <p class="mt-0 text-xs">
          Built with <a href="https://gohugo.io" target="_blank" rel="noopener noreferrer">Hugo</a> v0.143.1
          and <a href="https://github.com/mivinci/hugo-theme-minima" target="_blank" rel="noopener noreferrer">Minima</a>
        </p>
      </div>
      
      <p class="flex items-center mt-0">
        
          <a class="icon ml-1 mr-1" href="mailto:jarvis@apache.org" title="email">
          
            <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 21" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><path d="M22 6l-10 7L2 6"/></svg>
          
          </a>
        
          <a class="icon ml-1 mr-1" href="https://github.com/liunaijie" title="github">
          
            <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/></svg>
          
          </a>
        
          <a class="icon ml-1 mr-1" href="/index.xml" title="rss">
          
            <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 11a9 9 0 0 1 9 9M4 4a16 16 0 0 1 16 16"/><circle cx="5" cy="19" r="1"/></svg>
          
          </a>
        
      </p>
    </div>
  </div>
</footer>
</body>

</html>