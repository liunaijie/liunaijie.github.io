<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta property="og:url" content="https://www.liunaijie.top/coding/big_data/spark/%E9%85%8D%E7%BD%AE%E9%A1%B9/">
  <meta property="og:site_name" content="Jarvis`s library">
  <meta property="og:title" content="Spark-配置项">
  <meta property="og:description" content="内存相关配置项设置并行度, 并行度用spark.default.parallelism和spark.sql.shuffle.partitions 两个参数确定.
对于没有明确分区规则的RDD, 使用spark.default.parallelism来定义并行度 对于数据关联或聚合操作中可以使用spark.sql.shuffle.partitions来指定Reduce端的分区数量 什么是并行度: 指的是分布式数据集被划分为多少份, 从而用于分布式计算. 并行度的出发点是数据, 它明确了数据划分的粒度. 并行度越高, 数据的粒度越细, 数据分片越多, 数据越分散.
并行计算任务: 指的是在任意时刻整个集群能够同时计算的任务数量. 并行计算任务的出发点是计算任务, 是CPU. 由CPU有关的三个参数共同决定. — 具体说来，Executor 中并行计算任务数的上限是 spark.executor.cores 与 spark.task.cpus 的商，暂且记为 #Executor-tasks，整个集群的并行计算任务数自然就是 #Executor-tasks 乘以集群内 Executors 的数量，记为 #Executors。因此，最终的数值是：#Executor-tasks * #Executors。
并行度决定了数据粒度, 数据粒度决定了分区大小, 分区大小决定每个计算任务的内存消耗.
CPU相关配置项 CPU的配置项主要包括 spark.cores.max、spark.executor.cores 和 spark.task.cpus 这三个参数.
spark.cores.max — 限制整个job可以申请到的最大CPU数量, 当不设置时默认使用spark.deploy.defaultCores这个参数(默认为Integer.MAX_VALUE, 也就是不限制) spark.executor.cores — 设置单个executor可以使用的CPU资源, executor的数量可以通过($spark.cores.max / spark.executor.cores$)来确定 spark.task.cpus — 设置单个task消耗的CPU核数, 一个executor上并行执行的task数量可以通过($spark.executor.cores / spark.task.cpus$)来确定 内存相关配置项 Spark管理的内存分为堆内内存和堆外内存.
堆外内存又分为两个区域, Execution Memory和Storage Memory. 要想启用堆外内存, 需要将参数spark.memory.offHeap.enabled设置为true .然后再用spark.memory.offHeap.size 参数来指定堆外内存的大小">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="coding">
    <meta property="article:published_time" content="2022-04-01T00:00:00+00:00">
    <meta property="article:modified_time" content="2022-04-01T00:00:00+00:00">
    <meta property="article:tag" content="Spark">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Spark-配置项">
  <meta name="twitter:description" content="内存相关配置项设置并行度, 并行度用spark.default.parallelism和spark.sql.shuffle.partitions 两个参数确定.
对于没有明确分区规则的RDD, 使用spark.default.parallelism来定义并行度 对于数据关联或聚合操作中可以使用spark.sql.shuffle.partitions来指定Reduce端的分区数量 什么是并行度: 指的是分布式数据集被划分为多少份, 从而用于分布式计算. 并行度的出发点是数据, 它明确了数据划分的粒度. 并行度越高, 数据的粒度越细, 数据分片越多, 数据越分散.
并行计算任务: 指的是在任意时刻整个集群能够同时计算的任务数量. 并行计算任务的出发点是计算任务, 是CPU. 由CPU有关的三个参数共同决定. — 具体说来，Executor 中并行计算任务数的上限是 spark.executor.cores 与 spark.task.cpus 的商，暂且记为 #Executor-tasks，整个集群的并行计算任务数自然就是 #Executor-tasks 乘以集群内 Executors 的数量，记为 #Executors。因此，最终的数值是：#Executor-tasks * #Executors。
并行度决定了数据粒度, 数据粒度决定了分区大小, 分区大小决定每个计算任务的内存消耗.
CPU相关配置项 CPU的配置项主要包括 spark.cores.max、spark.executor.cores 和 spark.task.cpus 这三个参数.
spark.cores.max — 限制整个job可以申请到的最大CPU数量, 当不设置时默认使用spark.deploy.defaultCores这个参数(默认为Integer.MAX_VALUE, 也就是不限制) spark.executor.cores — 设置单个executor可以使用的CPU资源, executor的数量可以通过($spark.cores.max / spark.executor.cores$)来确定 spark.task.cpus — 设置单个task消耗的CPU核数, 一个executor上并行执行的task数量可以通过($spark.executor.cores / spark.task.cpus$)来确定 内存相关配置项 Spark管理的内存分为堆内内存和堆外内存.
堆外内存又分为两个区域, Execution Memory和Storage Memory. 要想启用堆外内存, 需要将参数spark.memory.offHeap.enabled设置为true .然后再用spark.memory.offHeap.size 参数来指定堆外内存的大小">

  
  
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#181818">
  <title>
    
    Jarvis`s library - Spark-配置项
    
  </title>
  
  
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
  
  
  
  <link rel="stylesheet" href="/minima.54cfcb44e10b4015b41a13771763013b79bdba6a92e49ea4a77bb44db465e761.css" integrity="sha256-VM/LROELQBW0GhN3F2MBO3m9umqS5J6kp3u0TbRl52E=">
  
  
  
  <script defer type="text/javascript" src="/minima.b4da24217e147f536fc7dc225886a1ea20bedabe7aed49e546a5d97cc34e4555.js" integrity="sha256-tNokIX4Uf1Nvx9wiWIah6iC&#43;2r567UnlRqXZfMNORVU="></script>
  
  
  
</head>
<script>
  const theme_config = 'system'
  const theme_light = theme_config === 'system' ? 'light' : theme_config;
  let theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : theme_light;
  console.debug(theme);

  try {
    localStorage.setItem('theme', theme);
    window.minima_theme = theme;
    document.querySelector('html').classList.add(theme);
  } catch (e) {
    console.error(e);
  }
</script>



<body>
  <header class="mt-3 mb-8">
  <div class="container mx-auto">
    <nav class="flex justify-between items-center">
      <div class="flex items-center">
        
        <div id="theme-switch" class="text-2xl cursor-pointer"></div>
      </div>
      <ul class="flex items-center text-base font-semibold
        whitespace-nowrap overflow-x-auto overflow-y-hidden">
        
        <li class="ml-2 mr-2">
          
          <a href='/'>首页</a>
          
        </li>
        
        <li class="ml-2 mr-2">
          
          <a href="/tags">标签</a>
          
        </li>
        
        <li class="ml-2 mr-2">
          
          <a href="/search">搜索</a>
          
        </li>
        
        <li class="ml-2 mr-2">
          
          <a href="/about">关于</a>
          
        </li>
        
      </ul>
      <ul class="flex item-center text-sm font-semibold">
        
        <li class="ml-2"><a href="https://www.liunaijie.top/"></a></li>
        
      </ul>
    </nav>
  </div>
</header>

  
<div class="container mx-auto">
  <h1 class="text-4xl font-extrabold mt-6 mb-6">Spark-配置项</h1>
  <div class="mb-3 text-sm flex justify-between ">
    <div>
      
      发布于 &mdash; 2022 年 04 月 01 日
      
      
    </div>
    
    <div>
      
      
      <a class="ml-1" href="/tags/Spark">#Spark</a>
      
    </div>
    
  </div>
  <main class="mb-8">
    <p></p>
    <article class="md">
      <p>内存相关配置项设置并行度, 并行度用<code>spark.default.parallelism</code>和<code>spark.sql.shuffle.partitions</code> 两个参数确定.</p>
<ul>
<li>对于没有明确分区规则的RDD, 使用<code>spark.default.parallelism</code>来定义并行度</li>
<li>对于数据关联或聚合操作中可以使用<code>spark.sql.shuffle.partitions</code>来指定Reduce端的分区数量</li>
</ul>
<p><strong>什么是并行度</strong>: 指的是分布式数据集被划分为多少份, 从而用于分布式计算. 并行度的出发点是数据, 它明确了数据划分的粒度. 并行度越高, 数据的粒度越细, 数据分片越多, 数据越分散.</p>
<p><strong>并行计算任务</strong>: 指的是在任意时刻整个集群能够同时计算的任务数量. 并行计算任务的出发点是计算任务, 是CPU. 由CPU有关的三个参数共同决定. — 具体说来，Executor 中并行计算任务数的上限是 spark.executor.cores 与 spark.task.cpus 的商，暂且记为 <code>#Executor-tasks</code>，整个集群的并行计算任务数自然就是 <code>#Executor-tasks</code> 乘以集群内 Executors 的数量，记为 <code>#Executors</code>。因此，最终的数值是：<code>#Executor-tasks * #Executors</code>。</p>
<p><strong>并行度决定了数据粒度, 数据粒度决定了分区大小, 分区大小决定每个计算任务的内存消耗.</strong></p>
<h2 id="cpu相关配置项">CPU相关配置项</h2>
<p>CPU的配置项主要包括 <code>spark.cores.max</code>、<code>spark.executor.cores</code> 和 <code>spark.task.cpus</code> 这三个参数.</p>
<ul>
<li>spark.cores.max — 限制整个job可以申请到的最大CPU数量, 当不设置时默认使用<code>spark.deploy.defaultCores</code>这个参数(默认为Integer.MAX_VALUE, 也就是不限制)</li>
<li>spark.executor.cores — 设置单个executor可以使用的CPU资源, executor的数量可以通过($spark.cores.max / spark.executor.cores$)来确定</li>
<li>spark.task.cpus — 设置单个task消耗的CPU核数, 一个executor上并行执行的task数量可以通过($spark.executor.cores / spark.task.cpus$)来确定</li>
</ul>
<h2 id="内存相关配置项">内存相关配置项</h2>
<p><img src="https://raw.githubusercontent.com/liunaijie/images/master/202308121607765.png" alt="">
<img src="https://raw.githubusercontent.com/liunaijie/images/master/202308121607158.png" alt="">
Spark管理的内存分为堆内内存和堆外内存.</p>
<p>堆外内存又分为两个区域, <code>Execution Memory</code>和<code>Storage Memory</code>. 要想启用堆外内存, 需要将参数<code>spark.memory.offHeap.enabled</code>设置为<code>true</code> .然后再用<code>spark.memory.offHeap.size</code> 参数来指定堆外内存的大小</p>
<p>堆内内存也分为四个区域, 分别是<code>Reserved Memory</code>, <code>User Memory</code>, <code>Execution Memory</code> 和 <code>Storage Memory</code></p>
<p>内存的基础配置项主要是5个:</p>
<ul>
<li>spark.executor.memory — 单个Executor中的堆内内存总大小</li>
<li>spark.memory.offHeap.size — 单个Executor中堆外内存总大小(当spark.memory.offHeap.enable为true才生效)</li>
<li>spark.memory.fraction — 堆内内存中, (用于缓存RDD和执行计算的内存之和)占可用内存的比例</li>
<li>spark.memory.storageFraction — 用于缓存RDD的内存占比, 执行内存占比为$(1-spark.memory.storageFraction)$</li>
<li>spark.rdd.compress — RDD缓存是否压缩, 默认不压缩</li>
</ul>
<h3 id="如何选择使用堆内内存或者是堆外内存">如何选择使用堆内内存或者是堆外内存</h3>
<p>堆外内存虽然更好的进行内存占用统计, 不需要垃圾回收机制, 不需要序列化与反序列化. 但是终归还是有缺点, 不然我们就无脑的使用堆外内存了.</p>
<p>我们来看一个例子: 这个表有4个字段</p>
<ul>
<li>int类型的userId</li>
<li>String类型的姓名</li>
<li>int类型的年龄</li>
<li>Char类型的性别</li>
</ul>
<p>当我们需要用字节数组来存储这条记录时, 由于无法事先知道String类型的长度, 所以只能在存储位置使用真正存储位置的offset来代替, 在offset位置的第一位表示String的长度, 从而完成这条记录的存储.
<img src="https://raw.githubusercontent.com/liunaijie/images/master/202308121608566.png" alt="">
Spark的堆外内存也是使用这种方式来存储应用的数据. 这种方式比JVM的存储更加紧凑, 从而节省来空间. 但是当我们的Schema变得复杂后, 维护这样一条记录的指针和偏移地址变得越来越多, 让字段的访问效率大打折扣, 而且指针多了之后, 内存泄漏的风险也变大了. Spark直接管理堆外内存的成本就变得非常高.</p>
<p><strong>对于需要处理的数据集，如果数据模式比较扁平，而且字段多是定长数据类型，就更多地使用堆外内存。相反地，如果数据模式很复杂，嵌套结构或变长字段很多，就更多采用 JVM 堆内内存会更加稳妥</strong></p>
<h3 id="user-memory与spark可用内存如何分配">User Memory与Spark可用内存如何分配</h3>
<p>现在Spark的<code>spark.memory.fraction</code>参数默认为<code>0.6</code> , 也就是默认会有60%的内存归Spark调用, 剩余的40%为User Memory.</p>
<p>User Memory主要存储开发者自定义的数据结构或Spark内部元数据.</p>
<p>如果应用中自定义数据结构不多, 可以适当调大<code>spark.memory.fraction</code>参数, 从而提高Spark用于分布式计算和缓存分布式数据集的内存大小.</p>
<h3 id="execution-memory与storage-memory如何平衡">Execution Memory与Storage Memory如何平衡</h3>
<p>统一内存管理模式下, 这两部分会互相占用. 当<code>Execution Memory</code>占用<code>Storage Memory</code>后, 需要执行完成后才会被释放, 而当<code>Storage Memory</code>占用<code>Execution Memory</code>时, 当Execution Memory需要则需要理解释放掉.</p>
<p>如果应用是“缓存密集型”的, 即需要反复遍历同一份分布式数据, 这个时候将数据缓存下来则可以提高效率. 即可以提高<code>spark.memory.storageFraction</code></p>
<p>但是, 还需要注意这两个之间的平衡.</p>
<p>当Storage Memory调大之后, 意味着Execution Memory变小了. 那么在执行关联, 排序, 聚合等需要消耗执行内存的任务时, 就会变慢.</p>
<p>由于Execution Memory变小, 在堆内创建新对象时, 由内存不足造成的垃圾回收也会影响执行效率.</p>
<p>还有一种方法是在进行缓存是将数据进行压缩, 这样相同的内存空间下就可以存储更多的数据, 可以修改<code>spark.rdd.compress</code>参数, 默认情况下是不使用压缩的</p>
<h2 id="磁盘相关配置项">磁盘相关配置项</h2>
<p><code>spark.local.dir</code> 这个参数可以运行开发者设置存储_RDD cache落盘数据块_和_Shuffle中间文件_的磁盘目录</p>
<h2 id="shuffle类配置项">Shuffle类配置项</h2>
<p>Shuffle分为Map和Reduce两个阶段. Map阶段按照Reducer的分区规则, 将中间数据写入到磁盘中, 然后Reduce阶段从各个Map节点拉取数据, 根据计算规则进行计算.</p>
<p><code>spark.shuffle.file.buffer</code> 和 <code>spark.reducer.maxSizeInFlight</code> 两个参数可以分别控制Map端和Reduce端的读写缓冲区大小.</p>
<p>Map阶段, 由于是先将数据写到内存(写缓存区)中, 当内存不足时再写到磁盘, 所以可以调大内存(写缓冲区)来减少<code>I/O</code>次数, 从而提高整体性能. 这个时候就需要调大<code>spark.shuffle.file.buffer</code> 参数.</p>
<p>Reduce阶段, Spark通过网络从不同Map节点的磁盘中拉取中间文件, 然后以数据块的形式暂存到Reduce节点的读缓冲区. 读缓冲区越大, 可以暂存的数据块也就越多, 拉取数据所需的网络请求次数也就越少, 单次请求的网络吞吐越高, 网络I/O的效率也就越高. 这个时候可以调节<code>spark.reducer.maxSizeInFlight</code> 来调大读缓冲区的大小, 提高性能.</p>
<p><strong>跳过排序</strong></p>
<p>spark从1.6版本开始, Spark统一采用Sort shuffle manager来管理Shuffle操作, 这时不管计算是否真的需要排序, 都会在Map阶段和Reduce阶段进行排序.</p>
<p>所以在不需要聚合，也不需要排序的计算场景中，我们就可以通过设置 <code>spark.shuffle.sort.bypassMergeThreshold</code> 的参数，来改变 Reduce 端的并行度（默认值是 200）。当 Reduce 端的分区数小于这个设置值的时候，我们就能避免 Shuffle 在计算过程引入排序。</p>

    </article>
  </main>
  

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css"
    integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js"
    integrity="sha384-YNHdsYkH6gMx9y3mRkmcJ2mFUjTd0qNQQvY9VYZgQd7DcN7env35GzlmFaZ23JGp"
    crossorigin="anonymous"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js"
    integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl"
    crossorigin="anonymous"></script>

<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            
            
            delimiters: [
                { left: '$$', right: '$$', display: true },
                { left: '$', right: '$', display: false },
                { left: '\\(', right: '\\)', display: false },
                { left: '\\[', right: '\\]', display: true }
            ],
            
            throwOnError: false
        });
    });
</script>





<script 
  src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"
  crossorigin="anonymous">
</script>
<script>
  mermaid.init(undefined, 'code.language-mermaid')
</script>




</div>


  <footer class="mt-8 mb-8">
  <div class="container mx-auto">
    <div class="mt-8 flex flex-col-reverse sm:flex-row sm:justify-between items-center">
      <div class="text-center sm:text-left">
        <p class="mt-0 text-sm"></p>
        <p class="mt-0 text-xs">
          Built with <a href="https://gohugo.io" target="_blank" rel="noopener noreferrer">Hugo</a> v0.143.1
          and <a href="https://github.com/mivinci/hugo-theme-minima" target="_blank" rel="noopener noreferrer">Minima</a>
        </p>
      </div>
      
      <p class="flex items-center mt-0">
        
          <a class="icon ml-1 mr-1" href="mailto:jarvis@apache.org" title="email">
          
            <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 21" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"/><path d="M22 6l-10 7L2 6"/></svg>
          
          </a>
        
          <a class="icon ml-1 mr-1" href="https://github.com/liunaijie" title="github">
          
            <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/></svg>
          
          </a>
        
          <a class="icon ml-1 mr-1" href="/index.xml" title="rss">
          
            <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 11a9 9 0 0 1 9 9M4 4a16 16 0 0 1 16 16"/><circle cx="5" cy="19" r="1"/></svg>
          
          </a>
        
      </p>
    </div>
  </div>
</footer>
</body>

</html>