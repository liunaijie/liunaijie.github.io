<!DOCTYPE html>
<html lang="zh-CN">

<head>

  <!-- Minima -->
  <!-- Hexo theme created by @adisaktijrs -->

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">

  
  <title>Spark-怎么用好AQE的三个特性</title>
  
  <link rel="canonical" href="https://www.liunaijie.top/2022/04/01/coding/big_data/spark/%E6%80%8E%E4%B9%88%E7%94%A8%E5%A5%BDAQE%E7%9A%84%E4%B8%89%E4%B8%AA%E7%89%B9%E6%80%A7/">
  
  <meta name="description" content="在2.0版本之前, Spark SQL仅仅支持启发式、静态的优化过程, 启发式的优化又叫RBO(Rule Based Optimization, 基于规则的优化), 它基于一些规则和策略实现, 如谓词下推、列剪枝. 这些规则和策略来源于数据库领域已有的应用经验. 启发式的优化是一种经验主义. 经验主">
  
  
  <meta name="keywords" content="blog">
  
  <meta name="author" content="Jarvis">
  
  
  
  <meta property="og:site_name" content="J.A.R.V.I.S" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="Spark-怎么用好AQE的三个特性" />
  
  <meta property="og:description" content="在2.0版本之前, Spark SQL仅仅支持启发式、静态的优化过程, 启发式的优化又叫RBO(Rule Based Optimization, 基于规则的优化), 它基于一些规则和策略实现, 如谓词下推、列剪枝. 这些规则和策略来源于数据库领域已有的应用经验. 启发式的优化是一种经验主义. 经验主">
  
  <meta property="og:url" content="https://www.liunaijie.top/2022/04/01/coding/big_data/spark/%E6%80%8E%E4%B9%88%E7%94%A8%E5%A5%BDAQE%E7%9A%84%E4%B8%89%E4%B8%AA%E7%89%B9%E6%80%A7/" />

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Spark-怎么用好AQE的三个特性">
  
  <meta name="twitter:description" content="在2.0版本之前, Spark SQL仅仅支持启发式、静态的优化过程, 启发式的优化又叫RBO(Rule Based Optimization, 基于规则的优化), 它基于一些规则和策略实现, 如谓词下推、列剪枝. 这些规则和策略来源于数据库领域已有的应用经验. 启发式的优化是一种经验主义. 经验主">
  
  
  
  
  <meta name="twitter:url" content="https://www.liunaijie.top/2022/04/01/coding/big_data/spark/%E6%80%8E%E4%B9%88%E7%94%A8%E5%A5%BDAQE%E7%9A%84%E4%B8%89%E4%B8%AA%E7%89%B9%E6%80%A7/" />

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Preload fonts
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="preload" href="/fonts/dm-serif-display-v4-latin-regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="/fonts/inter-v2-latin-regular.woff2" as="font" type="font/woff2" crossorigin>

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  
<link rel="stylesheet" href="/css/normalize.css">

  
<link rel="stylesheet" href="/css/skeleton.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
<link rel="stylesheet" href="/css/prism-dark.css">

  
<link rel="stylesheet" href="/css/prism-line-numbers.css">

  <!-- User css -->
  

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="/images/jarvis.png">

  <!-- Custom Theme Color Style
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <style>
  a:not(.icon) {
    text-decoration-color: #0FA0CE;
    background-image: linear-gradient(
      to bottom,
      rgba(0, 0, 0, 0) 50%,
      #0FA0CE 50%
    );
  }
  blockquote {
    border-left: 8px solid #0FA0CE;
  }
  .nanobar .bar {
    background: #0FA0CE;
  }
  .button.button-primary:hover,
  button.button-primary:hover,
  input[type="submit"].button-primary:hover,
  input[type="reset"].button-primary:hover,
  input[type="button"].button-primary:hover,
  .button.button-primary:focus,
  button.button-primary:focus,
  input[type="submit"].button-primary:focus,
  input[type="reset"].button-primary:focus,
  input[type="button"].button-primary:focus {
    background-color: #0FA0CE;
    border-color: #0FA0CE;
  }
  input[type="email"]:focus,
  input[type="number"]:focus,
  input[type="search"]:focus,
  input[type="text"]:focus,
  input[type="tel"]:focus,
  input[type="url"]:focus,
  input[type="password"]:focus,
  textarea:focus,
  select:focus {
    border: 1px solid #0FA0CE;
  }
</style>

  <!-- Google Analytics (With Privacy Settings On)
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  

  
  <script src="/js/pic.min.js" defer></script>
  

  

<meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="J.A.R.V.I.S" type="application/atom+xml">
</head>

<body>
  <div class="container">
    <div class="row">
      <div>

        <div class="row">
  <div class="two columns" style="max-width: 50px">
    <h1 class="mt-2 mode">
      <div onclick=setDarkMode(true) id="darkBtn"></div>
      <div onclick=setDarkMode(false) id="lightBtn" class=hidden></div>
      <script >
        if (localStorage.getItem('preferredTheme') == 'dark') {
          setDarkMode(true)
        }
        function setDarkMode(isDark) {
          var darkBtn = document.getElementById('darkBtn')
          var lightBtn = document.getElementById('lightBtn')
          if (isDark) {
            lightBtn.style.display = "block"
            darkBtn.style.display = "none"
            localStorage.setItem('preferredTheme', 'dark');
          } else {
            lightBtn.style.display = "none"
            darkBtn.style.display = "block"
            localStorage.removeItem('preferredTheme');
          }
          document.body.classList.toggle("darkmode");
        }
      </script>
    </h1>
  </div>

  <div class="six columns ml-1">
    <h1 class="mt-2">
      Jarvis&#39;s Blog
    </h1>
  </div>

  <div class="twelve columns">
    <div class="row">
      <div class="nine columns left">
        
          
          <a href="/" class="ml">Home</a>
          
        
          
          <a href="/categories/publish/" class="ml">Publish</a>
          
        
          
          <a href="/about" class="ml">About</a>
          
        
          
          <a href="/atom.xml" class="ml">Rss</a>
          
        
      </div>
    </div>
    <hr style="margin-bottom: 2.6rem">
  </div>
</div>

        <div class="trans">
            <h2>Spark-怎么用好AQE的三个特性</h2>

  <p>在2.0版本之前, Spark SQL仅仅支持启发式、静态的优化过程, 启发式的优化又叫RBO(Rule Based Optimization, 基于规则的优化), 它基于一些规则和策略实现, 如谓词下推、列剪枝. 这些规则和策略来源于数据库领域已有的应用经验. <strong>启发式的优化是一种经验主义.</strong></p>
<p>经验主义的弊端是对待相似的问题和场景都使用同一种套路.</p>
<p>在2.2版本中推出了CBO(Cost Based Optimization, 基于成本的优化), 特点是“实事求是”, 基于数据表的统计信息(如表大小、数据列分布)来选择优化策略. CBO支持的统计信息很丰富, 比如数据表的行数、每列的基数(Cardinality)、空间值、最大值、最小值和直方图等等. 因为有统计数据做支持, 所以CBO选择的优化策略往往优于RBO选择的优化规则.</p>
<p>但是CBO也有三个方面的缺点: 窄、慢、静.</p>
<ul>
<li>窄 : 指的是适用面太窄, CBO仅支持注册到Hive Metastore的数据表</li>
<li>慢: 指的是统计信息的搜集效率比较低. 对于注册到Hive Metastore的数据表, 开发者需要调用ANALYZE TABLE COMPUTE STATISTICS语句收集统计信息, 而各类信息的收集会消耗大量时间</li>
<li>静: 指的是静态优化, 这一点与RBO一样, CBO结合各类统计信息指定执行计划, 一旦执行计划交付运行, CBO的使命就算完成了. 也就是说如果在运行时数据分布发送动态变化, CBO先前制定的执行计划并不会跟着调整、适配</li>
</ul>
<h1 id="AQE是什么"><a href="#AQE是什么" class="headerlink" title="AQE是什么"></a>AQE是什么</h1><p>Spark在3.0推出了AQE(Adaptive Query Execution, 自适应查询执行). AQE是Spark SQL的一种动态优化机制, 在运行时, 每当Shuffle Map阶段执行完毕, AQE都会结合这个阶段的统计信息, 基于既定的规则动态的调整、修正尚未执行的逻辑计划和物理计划, 来完成对原始查询语句的运行时优化.</p>
<p><strong>AQE的优化机制触发的时机是Shuffle Map阶段执行完毕. 也就是说, AQE优化的频次与执行计划中Shuffle的次数一致.</strong> 如果查询语句没有引入Shuffle操作, 那么Spark SQL是不会触发AQE的.</p>
<h2 id="AQE依赖的统计信息是什么"><a href="#AQE依赖的统计信息是什么" class="headerlink" title="AQE依赖的统计信息是什么:"></a>AQE依赖的统计信息是什么:</h2><p>AQE赖以优化的统计信息与CBO不同, 这些统计信息并不是关于某张表或是哪个列, 而是<strong>Shuffle Map阶段输出的中间文件</strong>. 每个Map Task都会输出以data为后缀的数据文件, 还有以index为结尾的索引文件, 这些文件统称为中间文件. 每个data文件的大小、空文件数量与占比、每个Reduce Task对于的分区大小, 所有这些基于中间文件的统计值构成了AQE进行优化的信息来源.</p>
<p>AQE还会<strong>从运行时获取统计信息</strong>, 在条件允许的情况下, 优化决策会分别作用到逻辑计划和物理计划.</p>
<p>AQE既定的规则和策略主要有4个, 分为1个逻辑优化规则和3个物理优化策略<br><img src="https://raw.githubusercontent.com/liunaijie/images/master/202308121609085.png"></p>
<h2 id="如何用好AQE"><a href="#如何用好AQE" class="headerlink" title="如何用好AQE"></a>如何用好AQE</h2><p>首先回顾一下AQE动态优化的过程:</p>
<ul>
<li>Join策略调整 : 如果某张表在过滤之后, 尺寸小于广播变量阈值, 这张表参与的数据关联就会从Shuffle Sort Merge Join降级(Demote)为执行效率更高的Broadcast Hash Join.</li>
<li>自动分区合并 : 在Shuffle之后, Reduce Task数据分布参差不齐, AQE将自动合并过小的数据分区</li>
<li>自动倾斜处理 : 结合配置项, AQE自动拆分Reduce阶段过大的数据分区, 降低单个Reduce Task的工作负载</li>
</ul>
<h3 id="Join策略调整"><a href="#Join策略调整" class="headerlink" title="Join策略调整"></a>Join策略调整</h3><p>这个特性设计了一个逻辑规则和一个物理策略, 它们分别是DemoteBroadcastHashJoin和OptimizeLocalShuffleReader.</p>
<p>DemoteBroadcastHashJoin规则的作用, 是把Shuffle Joins降级为Broadcast Joins. 需要注意的是, 这个规则仅适用于Shuffle Sort Merge Join这种关联机制, 其他机制如Shuffle Hash Join、Shuffle Nested Loop Join都不支持. 对于参与Join的两张表来说, 在它们分别完成了Shuffle Map阶段的计算之后, DemoteBroadcastJoin会判断中间文件是否满足如下条件</p>
<ul>
<li>中间文件尺寸总和小于广播阈值 spark.sql.autoBroadcastJoinThreshold</li>
<li>空文件占比小于配置项 spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin</li>
</ul>
<p>只要有任意一张表的统计信息满足这两个条件, Shuffle Sort Merge Join就会降级为Broadcast Hash Join.</p>
<p>AQE依赖的统计信息来自于Shuffle Map阶段生成的中间文件, 这意味着AQE在开始优化之前, Shuffle操作就已经执行过半了.</p>
<p>OptimizeLocalShuffleReader物理策略可以在大表已经完成Shuffle Map阶段后, 不再进行网络分发, 将Reduce Task改为就地读取本地节点的中间文件, 完成与小表的关联操作.</p>
<p>OptimizeLocalShuffleRead物理策略的生效由一个配置项<code>spark.sql.adaptive.localShuffleRead.enable</code> 决定, 默认值为True.</p>
<h3 id="自动分区合并"><a href="#自动分区合并" class="headerlink" title="自动分区合并"></a>自动分区合并</h3><p>在Reduce阶段, 当Reduce Task从全网把数据拉回, AQE按照分区编号的顺序, 依次把小于目标尺寸的分区合并在一起.</p>
<p>目标分区尺寸由以下两个参数共同决定:</p>
<ul>
<li>spark.sql.adaptive.advisoryPartitionSizeInBytes 由开发者指定分区合并后的推荐尺寸</li>
<li>spark.sql.adaptive.coalescePartitions.minPartitionNum 最小分区数量, 分区合并后, 分区数不能小于该值</li>
</ul>
<p>在Shuffle Map阶段完成之后, AQE优化机制被触发, CoalesceShufflePartitions策略“无条件”地被添加到新的物理计划中. 读取配置项、计算目标分区大小、依序合并相邻分区这些计算逻辑, 在Tungsten WSCG的作用下融合进“手写代码”于Reduce阶段执行.</p>
<h3 id="自动倾斜处理"><a href="#自动倾斜处理" class="headerlink" title="自动倾斜处理"></a>自动倾斜处理</h3><p>于自动分区合并相反, 自动倾斜处理的操作是“拆”, 在Reduce阶段, 当Reduce Task所需处理的分区尺寸大于一定阈值时, 利用OptimizeSkewedJoin策略, AQE会把大分区拆分成多个小分区.</p>
<p>倾斜分区和拆分粒度由以下配置项决定:</p>
<ul>
<li>spark.sql.adaptive.skewJoin.skewedPartitionFactor 判断倾斜的膨胀系数</li>
<li>spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes 判断倾斜的最低阈值</li>
<li>spark.sql.adaptive.advisoryPartitionSizeInBytes 以字节为单位, 定义拆分粒度</li>
</ul>
<p>自动倾斜处理的拆分操作也是在Reduce阶段执行的. 在同一个Executor内部, 本该由一个Task去处理的大分区, 被AQE拆分成多个小分区并交由多个Task去计算. 这样Task之间的计算负载就可以得到平衡. 但是, 这并没有解决Executors之间的负载均衡问题.</p>
<p>这里的拆分只是将一次执行的大任务分成多个小任务, 但是这些任务还都是在一个Executor上执行的, 从总体来看, 还是存在单个Executor的倾斜问题.</p>
<p>问题:</p>
<ol>
<li><p>对于Join的两张表, 如果表1有倾斜, 表2不存在倾斜, 那么只需要对表1进行拆分, 但是这时为了保证关联关系不被破坏, 还需要对表2对应的数据分区做复制.</p>
</li>
<li><p>如果两张表都存在倾斜. 这时将表1拆分为2份, 表2拆分为2份. 为了不破坏逻辑上的关联关系</p>
<p>表1、表2拆分出来的分区还要各自复制一份.</p>
<p>当左表拆除M个分区, 右表拆分出N个分区, 那么每张表都需要保持M*N份分区数据, 才能保证关联逻辑的一致性. 当M, N逐渐变大时, AQE处理数据倾斜所需要的计算开销将会面临失控的风险</p>
</li>
</ol>
<p>总的来说, 当应用中的数据倾斜比较简单, 比如虽然有倾斜但数据分布相对均匀, 或是关联计算中只有一边有倾斜, 我们完全可以依赖AQE的自动倾斜处理机制. 但是, 在应用中倾斜十分复杂时就需要衡量AQE的自动倾斜处理与手动处理倾斜之间的关系.</p>
<h2 id="AQE小结"><a href="#AQE小结" class="headerlink" title="AQE小结"></a>AQE小结</h2><p>AQE是Spark SQL的一种动态优化策略, 它的诞生解决了RBO、CBO, 这些启发式、静态优化机制的局限性.</p>
<p>AQE在Shuffle Map阶段执行完毕, 都会结合这个阶段的统计信息, 根据既定的规则和策略动态的调整、修正尚未执行的逻辑计划和物理计划, 从而完成对原始查询语句的运行时优化. 因此, 只有当查询语句会引入Shuffle操作时, Spark SQL才会触发AQE.</p>
<p>AQE支持的三种优化特性分别是Join策略调整、自动分区合并和自动倾斜处理</p>
<p>关于Join策略调整, DemoteBroadcastHashJoin规则仅仅适用于Shuffle Sort Merge Join这种关联机制, 对于其他Shuffle Joins类型, AQE暂不支持把它们转化为Broadcast Joins. 其次, 为了确保AQE的Join策略调整正常运行, 要确保spark.sql.adaptive.localShuffleReader.enabled配置为开启状态</p>
<p>关于自动分区合并, 在Shuffle Map阶段完成之后, 结合分区推荐尺寸与分区数量限制, AQE会自动帮我们完成分区合并的计算过程</p>
<p>关于AQE的自动倾斜处理, 它只能以Task为粒度缓解数据倾斜, 并不能解决不同Executors之间的负载均衡问题.</p>

<br>
<h2>Tags: </h2>
  <p><a class="classtest-link" href="/tags/big-data-spark/" rel="tag">big_data/spark</a> — 2022年4月1日</p>
  

  <script async src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
  });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

  <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
<script>
  $(document).ready(() => {
    const maraidConfig = {
      theme: "default",
      logLevel: 3,
      flowchart: { curve: "linear" },
      gantt: { axisFormat: "%m/%d/%Y" },
      sequence: { actorMargin: 50 },
    };
    mermaid.initialize(maraidConfig);
  });
</script>

        </div>
        <!-- <div class="row mt-2">
  <h3>Search</h3>
  <div><input id="search-text" title="search" class="search-text" type="text" placeholder="search......"></div>
  <div style="margin-top: 1.5rem;">
    <ul id="result"></ul>
  </div>
</div> -->
        <div class="row mt-2">
  
    <div class="eight columns">
      <p id="madewith">Made with ❤ and
        <a class="footer-link icon" href="https://hexo.io" target="_blank" style="text-decoration: none;" rel="noreferrer" aria-label="Hexo.io">
        <svg class="hexo svg-hov" width="14" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><title>Hexo.js</title><path d="M12 .007L1.57 6.056V18.05L12 23.995l10.43-6.049V5.952L12 .007zm4.798 17.105l-.939.521-.939-.521V12.94H9.08v4.172l-.94.521-.938-.521V6.89l.939-.521.939.521v4.172h5.84V6.89l.94-.521.938.521v10.222z"/></svg>
        </a>
        
    </div>

    <!-- Sepcial thanks to https://simpleicons.org/ for the icons -->
    <div class="four columns mb-3 posisi" >
      
      <a class="ml-0 footer-link icon" href="https://github.com/liunaijie" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="GitHub">
        <svg class="github svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      </a>
      

      

      

      

      
      
        <a class="ml-0 footer-link icon" href="mailto:jarvis@apache.org" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="Email">
          <svg class="email svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Email</title><path d="M12 12.713l11.985-7.99c-.01-.01-11.985-7.723-11.985-7.723s-11.975 7.713-11.985 7.723l11.985 7.99zm0 2.287l-12-8v14h24v-14l-12 8z"/></svg>
        </a>
        
    </div>
  
</div>

      </div>

    </div>

  </div>
  <script src="/js/nanobar.min.js"></script>

  <script>
    var options = {
      classname: 'nanobar',
      id: 'myNanobar'
    };
    var nanobar = new Nanobar(options);
    nanobar.go(30);
    nanobar.go(76);
    nanobar.go(100);
  </script>

</body>

</html>